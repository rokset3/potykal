{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Preparing repo :D"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-21T01:16:21.168761Z","iopub.status.busy":"2023-07-21T01:16:21.168235Z","iopub.status.idle":"2023-07-21T01:16:21.189249Z","shell.execute_reply":"2023-07-21T01:16:21.188274Z","shell.execute_reply.started":"2023-07-21T01:16:21.168730Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing model.py\n"]}],"source":["%%writefile model.py\n","\n","import os\n","import random\n","import math\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","from einops import rearrange, reduce, repeat\n","from torch import einsum \n","\n","import numpy as np\n","\n","\n","\n","class GPT(nn.Module):\n","    def __init__(self,\n","                 vocab_size,\n","                 num_layers,\n","                 num_heads,\n","                 hidden_dim,\n","                 ffc_hidden_dim,\n","                 attn_dropout_p=0.1,\n","                 ffc_dropout_p=0.1,\n","                 max_seq_len=512,\n","                 ):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.num_layers = num_layers\n","        self.num_heads = num_heads\n","        self.hidden_dim = hidden_dim\n","        self.ffc_hidden_dim = ffc_hidden_dim\n","        self.attn_dropout_p = attn_dropout_p\n","        self.ffc_dropout_p = ffc_dropout_p\n","        self.max_seq_len = max_seq_len\n","\n","        self.decoder_block = nn.ModuleList([DecoderLayer(self.num_heads,\n","                                                         self.hidden_dim,\n","                                                         self.ffc_hidden_dim,\n","                                                         self.attn_dropout_p,\n","                                                         self.ffc_dropout_p) for _ in range(self.num_layers)])\n","        \n","        self.pos_embeddings = nn.Embedding(self.max_seq_len, self.hidden_dim)\n","        self.token_embeddings = nn.Embedding(self.vocab_size, self.hidden_dim)\n","\n","        self.proj_layer = nn.Linear(self.hidden_dim, self.vocab_size)\n","        \n","        self.register_buffer('tril',\n","                             torch.tril(torch.ones(self.max_seq_len, self.max_seq_len)).bool())\n","        self.register_buffer('pos_ids',\n","                             torch.arange(self.max_seq_len))\n","    \n","\n","\n","    def forward(self,\n","                input_tokens,\n","                tokenizer_mask=None):\n","        seq_len = input_tokens.shape[-1]\n","        b_size = input_tokens.shape[0]\n","        \n","        mask = self.make_attn_mask(seq_len, b_size, tokenizer_mask)\n","        \n","        x = self.pos_embeddings(self.pos_ids[:seq_len]) + self.token_embeddings(input_tokens)\n","\n","        for layer in self.decoder_block:\n","            x = layer(x)\n","        x = self.proj_layer(x)\n","        return x\n","\n","\n","    def make_attn_mask(self, seq_len, b_size, tokenizer_mask=None):\n","        mask = self.tril[:seq_len, :seq_len].unsqueeze(0).repeat(b_size, 1, 1)\n","        \n","        if tokenizer_mask is not None:\n","            mask = mask & tokenizer_mask.bool().unsqueeze(1)\n","        return mask\n","\n","class MSALayer(nn.Module):\n","    def __init__(self,\n","                 num_heads,\n","                 hidden_dim,\n","                 attn_dropout_p=0.1\n","                 ):\n","        \n","        assert hidden_dim % num_heads == 0\n","        \n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.hidden_dim = hidden_dim\n","        self.head_dim = self.hidden_dim // self.num_heads\n","        self.attn_dropout_p = attn_dropout_p\n","\n","        self.toq = nn.Linear(self.hidden_dim, self.hidden_dim)\n","        self.tok = nn.Linear(self.hidden_dim, self.hidden_dim)\n","        self.tov = nn.Linear(self.hidden_dim, self.hidden_dim)\n","        self.ffc = nn.Linear(self.hidden_dim, self.hidden_dim)\n","\n","        self.layer_norm = nn.LayerNorm(normalized_shape=self.hidden_dim)\n","        self.attn_dropout = nn.Dropout(p=self.attn_dropout_p if self.attn_dropout_p else 0)\n","\n","    def forward(self,\n","                x,\n","                mask=None):\n","        # shape of input is [b_size, seq_len, hidden_dim]\n","        q = self.toq(x)\n","        k = self.tok(x)\n","        v = self.tov(x)\n","        \n","        q = rearrange(q, 'b s (num_heads h) -> (b num_heads) s h', num_heads=self.num_heads)\n","        k = rearrange(k, 'b s (num_heads h) -> (b num_heads) s h', num_heads=self.num_heads)\n","        v = rearrange(v, 'b s (num_heads h) -> (b num_heads) s h', num_heads=self.num_heads)\n","\n","        output, probs = attn_function(q, k, v, mask=mask, attn_dropout=self.attn_dropout)\n","\n","        output = rearrange(output, '(b num_heads) s h -> b s (num_heads h)', num_heads=self.num_heads)\n","        output = self.ffc(output)\n","\n","        output = self.layer_norm(output + x)\n","        return output, probs\n","        \n","        \n","class DecoderLayer(nn.Module):\n","    def __init__(self, \n","                 num_heads,\n","                 hidden_dim,\n","                 ffc_hidden_dim,\n","                 attn_dropout_p=0.1,\n","                 ffc_dropout_p=0.1,\n","                 ):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.hidden_dim = hidden_dim\n","        self.ffc_hidden_dim = ffc_hidden_dim\n","        self.attn_dropout_p = attn_dropout_p\n","        self.ffc_dropout_p = ffc_dropout_p\n","\n","        self.ffc_layer = nn.Sequential(\n","            nn.Linear(self.hidden_dim, self.ffc_hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(p=self.ffc_dropout_p),\n","            nn.Linear(self.ffc_hidden_dim, self.hidden_dim)\n","        ) \n","        self.ffc_layer_norm = nn.LayerNorm(normalized_shape=self.hidden_dim)\n","\n","        self.msalayer = MSALayer(self.num_heads,\n","                                 self.hidden_dim,\n","                                 self.attn_dropout_p,)\n","\n","    def forward(self,\n","                x,\n","                mask=None):\n","        res = x\n","        x, _ = self.msalayer(x, mask=mask)\n","        \n","        return self.ffc_layer_norm(self.ffc_layer(x) + res)\n","    \n","\n","def attn_function(q, k, v, mask=None, attn_dropout=None):\n","    \n","    #q, k, v shape is [b, s, h]\n","    b_size = q.shape[0]\n","    seq_len = q.shape[1]\n","    hidden_dim = q.shape[2]\n","\n","\n","    scaled_dot_product = einsum('bsh, bvh -> bsv', [q, k])/math.sqrt(hidden_dim)\n","\n","    if mask:\n","        scaled_dot_product = scaled_dot_product.masked_fill(mask==False, 1e-9)\n","    \n","    if attn_dropout:\n","        scaled_dot_product = attn_dropout(scaled_dot_product)\n","    \n","    attn_probs = F.softmax(scaled_dot_product, dim=-1)\n","    attn_output = einsum('bsv, bvd -> bsd', [attn_probs, v])\n","\n","    return attn_output, attn_probs"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:18:06.520925Z","iopub.status.busy":"2023-07-21T01:18:06.520541Z","iopub.status.idle":"2023-07-21T01:18:06.529803Z","shell.execute_reply":"2023-07-21T01:18:06.528670Z","shell.execute_reply.started":"2023-07-21T01:18:06.520892Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting train_tokenizer.py\n"]}],"source":["%%writefile train_tokenizer.py\n","from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","from tokenizers.processors import TemplateProcessing\n","\n","if __name__ == \"__main__\":\n","    tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n","    trainer = BpeTrainer(special_tokens=[\"<unk>\",\n","                                         \"<s>\",\n","                                         \"<pad>\",\n","                                         \"<bos>\",\n","                                         ], vocab_size=5000) #i took 5k just randomly\n","    tokenizer.pre_tokenizer = Whitespace()\n","\n","    files = [\"data/input.txt\"]\n","    tokenizer.train(files, trainer)\n","\n","    tokenizer.post_processor = TemplateProcessing(\n","        single=\"<bos> $A <s>\",\n","        special_tokens=[\n","            (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n","            (\"<bos>\", tokenizer.token_to_id(\"<bos>\")),\n","            (\"<pad>\", tokenizer.token_to_id(\"<pad>\"))\n","        ],\n","    )\n","    tokenizer.enable_padding(pad_id=2, pad_token=\"<pad>\")\n","    tokenizer.save(\"data/tokenizer.json\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:46:07.822442Z","iopub.status.busy":"2023-07-21T01:46:07.821609Z","iopub.status.idle":"2023-07-21T01:46:07.831652Z","shell.execute_reply":"2023-07-21T01:46:07.830575Z","shell.execute_reply.started":"2023-07-21T01:46:07.822401Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing objects.py\n"]}],"source":["%%writefile objects.py\n","\n","import numpy as np\n","import torch\n","\n","from torch.utils.data import Dataset\n","from tokenizers import Tokenizer\n","from typing import List\n","\n","\n","class ConstantLenghtDataset(Dataset):\n","    def __init__(self, \n","                 texts: List[str],\n","                 tokenizer: Tokenizer,\n","                 length: int=512,):\n","        self.texts = texts\n","        self.length = length\n","        self.tokenizer = tokenizer\n","        self.tokenizer.no_padding()\n","\n","        encoded_text = tokenizer.encode_batch(self.texts)\n","        tokens_num = [len(s.tokens) for s in encoded_text]\n","        constant_len_dataset_ids = []\n","        concat_sentences_ids = []\n","        sum=0\n","        \n","        for idx, num in enumerate(tokens_num):\n","            if sum > 512:\n","                constant_len_dataset_ids.append(concat_sentences_ids)\n","                concat_sentences_ids = []\n","                sum = 0\n","\n","            concat_sentences_ids.append(idx)\n","            sum+=num\n","        \n","        np_text = np.array(self.texts)\n","        new_dataset = []\n","        for idxs in constant_len_dataset_ids:\n","            new_dataset.append(' '.join(np_text[idxs].tolist()))\n","\n","        self.dataset = new_dataset\n","\n","    def __len__(self,):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n","    \n","class TokenizerWrapper():\n","    def __init__(self,\n","                 tokenizer,\n","                 pad_seq_len=512):\n","        self.tokenizer = tokenizer\n","        self.pad_seq_len = pad_seq_len\n","        self.tokenizer.enable_padding(pad_id=2, pad_token=\"<pad>\", length=pad_seq_len)\n","        self.vocab_size = self.tokenizer.get_vocab_size()\n","\n","    def __call__(self, input_sentences: List[str], batch=True):\n","        output = {}\n","        if batch:\n","            encoded_input = self.tokenizer.encode_batch(input_sentences)\n","            ids = torch.tensor([input.ids for input in encoded_input], requires_grad=False)\n","            attn_masks = torch.tensor([input.attention_mask for input in encoded_input], requires_grad=False)\n","        else:\n","            encoded_input = self.tokenizer.encode(input_sentences)\n","            ids = torch.tensor(encoded_input.ids, requires_grad=False).unsqueeze(0)\n","            attn_masks = torch.tensor(encoded_input.attention_mask, requires_grad=False).unsqueeze(0)\n","            \n","        output['input_ids'] = ids\n","        output['attn_mask'] = attn_masks\n","\n","        return output"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:52:06.590094Z","iopub.status.busy":"2023-07-21T01:52:06.589475Z","iopub.status.idle":"2023-07-21T01:52:06.598855Z","shell.execute_reply":"2023-07-21T01:52:06.597794Z","shell.execute_reply.started":"2023-07-21T01:52:06.590053Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting utils.py\n"]}],"source":["%%writefile utils.py\n","import os\n","\n","import torch\n","import torch.distributed as dist\n","import torch.nn as nn\n","\n","from tqdm import tqdm\n","\n","def setup(rank, world_size):\n","    os.environ['MASTER_ADDR'] = 'localhost'\n","    os.environ['MASTER_PORT'] = '8080'\n","\n","    # initialize the process group\n","    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n","    dist.barrier()\n","    \n","def cleanup():\n","    dist.destroy_process_group()\n","    \n","    \n","def train(epoch, model, optimizer, train_dataloader, tokenizerwrapped, scaler):\n","    model.train()\n","    training_loss = 0\n","    tokenizerwrapped.tokenizer.enable_padding(pad_id=2, pad_token=\"<pad>\", length=tokenizerwrapped.pad_seq_len)\n","    for batch_num, batch in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        \n","        inputs = tokenizerwrapped(batch)\n","        labels = inputs['input_ids'].cuda(non_blocking=True)\n","        attn_mask = inputs['attn_mask'].cuda(non_blocking=True)\n","        \n","        with torch.cuda.amp.autocast(enabled=True):\n","            logits = model(labels, attn_mask)\n","        \n","            shift_logits = logits[..., :-1, :].contiguous()\n","            shift_labels = labels[..., 1:].contiguous()\n","        \n","            loss_fn = nn.CrossEntropyLoss()\n","            loss = loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))        \n","        \n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        \n","        training_loss += loss.item()\n","\n","    training_loss /= batch_num\n","    print(f\"Epoch: {epoch}, Training loss: {training_loss}\")\n","\n","def test(epoch, model, test_dataloader, tokenizerwrapped):\n","    model.eval()\n","    test_loss = 0\n","    tokenizerwrapped.tokenizer.enable_padding(pad_id=2, pad_token=\"<pad>\", length=tokenizerwrapped.pad_seq_len)\n","    with tqdm(total=len(test_dataloader.dataset)) as progress_bar:\n","        with torch.no_grad():\n","            for batch_idx, batch in enumerate(test_dataloader):\n","                inputs = tokenizerwrapped(batch)\n","                labels = inputs['input_ids'].cuda(non_blocking=True)\n","                attn_mask = inputs['attn_mask'].cuda(non_blocking=True)\n","\n","                logits = model(labels, attn_mask)\n","                \n","                shift_logits = logits[..., :-1, :].contiguous()\n","                shift_labels = labels[..., 1:].contiguous()\n","        \n","                loss_fn = nn.CrossEntropyLoss()\n","                loss = loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","                \n","                test_loss += loss.item()\n","                progress_bar.update(labels.size(0))\n","            \n","            test_loss /= batch_idx\n","    \n","    return test_loss\n","\n","\n","def prepare_data():\n","    with open('data/input.txt', 'r') as f:\n","        input_text = f.readlines()\n","    input_text = [i for i in input_text if i!='\\n']\n","    train_size = 0.9\n","    train_ids = int(len(input_text) * train_size)\n","    train_data = input_text[: train_ids]\n","    test_data = input_text[train_ids:]\n","    \n","    return train_data, test_data"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:56:32.440020Z","iopub.status.busy":"2023-07-21T01:56:32.439616Z","iopub.status.idle":"2023-07-21T01:56:32.450825Z","shell.execute_reply":"2023-07-21T01:56:32.449738Z","shell.execute_reply.started":"2023-07-21T01:56:32.439987Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting main.py\n"]}],"source":["%%writefile main.py\n","import os\n","import sys\n","from time import time_ns\n","\n","import numpy as np\n","import random\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import torch.distributed as dist\n","import torch.multiprocessing as mp\n","import torch.backends.cudnn as cudnn\n","\n","\n","from tokenizers import Tokenizer\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","from torch.utils.data.distributed import DistributedSampler\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","from model import GPT\n","from state import load_checkpoint, save_checkpoint\n","from objects import ConstantLenghtDataset, TokenizerWrapper\n","from utils import (setup, cleanup, train, test, prepare_data)\n","\n","\n","\n","tokenizer = Tokenizer.from_file(\"data/tokenizer.json\")\n","model_config = dict(\n","    num_layers=12,\n","    num_heads=12,\n","    hidden_dim=768,\n","    ffc_hidden_dim=3072,\n","    max_seq_len=512,\n","    vocab_size=tokenizer.get_vocab_size()\n",")\n","\n","tokenizerwrapped = TokenizerWrapper(tokenizer, pad_seq_len=model_config['max_seq_len'])\n","\n","\n","\n","\n","\n","train_texts, test_texts = prepare_data()\n","\n","train_dataset = ConstantLenghtDataset(train_texts, tokenizer, length=model_config['max_seq_len'])\n","test_dataset = ConstantLenghtDataset(test_texts, tokenizer, length=model_config['max_seq_len'])\n","\n","NUM_EPOCHS = 200\n","WORLD_SIZE = 2\n","BATCH_SIZE = 32\n","LR = 2e-5\n","SAVE_INTERVAL=10\n","SAVE_PATH = \"checkpoints/model.pt\"\n","\n","\n","\n","\n","def demo_basic(rank, world_size):\n","    print(f\"Running basic GPT-1 traning on device: {rank}.\")\n","    setup(rank, world_size)\n","    \n","    torch.cuda.set_device(rank)\n","    train_sampler = DistributedSampler(\n","        train_dataset,\n","        num_replicas=world_size,\n","        rank=rank,\n","        shuffle=True\n","    )\n","    \n","    train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n","                              shuffle=False, num_workers=2, pin_memory=True, sampler=train_sampler)\n","    \n","    test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n","                            shuffle=False, num_workers=2, pin_memory=True)\n","\n","    \n","    \n","    model = GPT(**model_config).cuda(rank)\n","    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, nesterov=True)\n","    model = DDP(model, device_ids=[rank])\n","    state = load_checkpoint(SAVE_PATH, rank, model, optimizer)\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=True)\n","\n","    cudnn.benchmark = True\n","    \n","    for epoch in range(NUM_EPOCHS):\n","        t0 = time_ns()\n","\n","        train(epoch, model, optimizer, train_dataloader, tokenizerwrapped, scaler)\n","\n","        t1 = time_ns()\n","        delta = (t1 - t0) / (10 ** 9)\n","        print(f\"Device {rank} - Train time: {delta} sec\")\n","        \n","        if rank == 0:\n","            loss = test(epoch, model, test_dataloader, tokenizerwrapped)\n","            print(f\"Loss: {loss}%\")\n","\n","        if epoch in [int(NUM_EPOCHS * 0.5), int(NUM_EPOCHS * 0.75)]:\n","            optimizer.param_groups[0]['lr'] /= 10.\n","            \n","        if epoch % SAVE_INTERVAL == 0 and rank == 0:\n","            save_checkpoint(state, SAVE_PATH)\n","\n","    state.epoch = epoch\n","    cleanup()\n","    \n","    \n","def run_demo(demo_fn, world_size):\n","    mp.spawn(demo_fn,\n","             args=(world_size,),\n","             nprocs=world_size,\n","             join=True)\n","    \n","    \n","if __name__ == '__main__':\n","    run_demo(demo_basic,\n","             2)"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting state.py\n"]}],"source":["%%writefile state.py\n","import torch\n","import os\n","\n","class State:\n","    \"\"\"\n","    Container for objects that we want to checkpoint. Represents the\n","    current \"state\" of the worker. This object is mutable.\n","    \"\"\"\n","\n","    def __init__(self, model, optimizer):\n","        self.epoch = -1\n","        self.model = model\n","        self.optimizer = optimizer\n","\n","\n","    def capture_snapshot(self):\n","        \"\"\"\n","        Essentially a ``serialize()`` function, returns the state as an\n","        object compatible with ``torch.save()``. The following should work\n","        ::\n","        snapshot = state_0.capture_snapshot()\n","        state_1.apply_snapshot(snapshot)\n","        assert state_0 == state_1\n","        \"\"\"\n","        return {\n","            \"epoch\": self.epoch,\n","            \"model\": self.model.state_dict(),\n","            \"optimizer\": self.optimizer.state_dict(),\n","        }\n","\n","    def apply_snapshot(self, obj, device_id):\n","        \"\"\"\n","        The complimentary function of ``capture_snapshot()``. Applies the\n","        snapshot object that was returned by ``capture_snapshot()``.\n","        This function mutates this state object.\n","        \"\"\"\n","\n","        self.epoch = obj[\"epoch\"]\n","        self.model.load_state_dict(obj[\"model\"])\n","        self.optimizer.load_state_dict(obj[\"optimizer\"])\n","\n","    def save(self, f):\n","        torch.save(self.capture_snapshot(), f, _use_new_zipfile_serialization=False)\n","\n","    def load(self, f, device_id):\n","        # Map model to be loaded to specified single gpu.\n","        snapshot = torch.load(f, map_location=f\"{device_id}\")\n","        self.apply_snapshot(snapshot, device_id)\n","\n","\n","def save_checkpoint(state: State, filename):\n","    checkpoint_dir = os.path.dirname(filename)\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    state.save(filename)\n","    print(f\"=> saved checkpoint for epoch {state.epoch} at {filename}\")\n","\n","\n","def load_checkpoint(checkpoint_file, device_id, model, optimizer) -> State:\n","    state = State(model, optimizer)\n","\n","    if os.path.isfile(checkpoint_file):\n","        print(f\"=> loading checkpoint file: {checkpoint_file}\")\n","        state.load(checkpoint_file, device_id)\n","        print(f\"=> loaded checkpoint file: {checkpoint_file}\")\n","    return state\n"]},{"cell_type":"markdown","metadata":{},"source":["# Code execution part"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:44:55.421920Z","iopub.status.busy":"2023-07-21T01:44:55.420964Z","iopub.status.idle":"2023-07-21T01:45:18.832940Z","shell.execute_reply":"2023-07-21T01:45:18.831605Z","shell.execute_reply.started":"2023-07-21T01:44:55.421874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tokenizers in ./gas_project_env/lib/python3.8/site-packages (0.13.3)\n","Requirement already satisfied: einops in ./gas_project_env/lib/python3.8/site-packages (0.6.1)\n","Requirement already satisfied: torch in ./gas_project_env/lib/python3.8/site-packages (2.0.1)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (11.7.99)\n","Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (2.0.0)\n","Requirement already satisfied: typing-extensions in ./gas_project_env/lib/python3.8/site-packages (from torch) (4.7.1)\n","Requirement already satisfied: networkx in ./gas_project_env/lib/python3.8/site-packages (from torch) (3.1)\n","Requirement already satisfied: sympy in ./gas_project_env/lib/python3.8/site-packages (from torch) (1.12)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (10.2.10.91)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (11.10.3.66)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (11.7.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (2.14.3)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (8.5.0.96)\n","Requirement already satisfied: jinja2 in ./gas_project_env/lib/python3.8/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (11.7.4.91)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (11.4.0.1)\n","Requirement already satisfied: filelock in ./gas_project_env/lib/python3.8/site-packages (from torch) (3.12.2)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in ./gas_project_env/lib/python3.8/site-packages (from torch) (11.7.101)\n","Requirement already satisfied: setuptools in ./gas_project_env/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (68.0.0)\n","Requirement already satisfied: wheel in ./gas_project_env/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (0.40.0)\n","Requirement already satisfied: lit in ./gas_project_env/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (16.0.6)\n","Requirement already satisfied: cmake in ./gas_project_env/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (3.26.4)\n","Requirement already satisfied: mpmath>=0.19 in ./gas_project_env/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in ./gas_project_env/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n"]}],"source":["!pip install tokenizers\n","!pip install einops\n","!pip install torch"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:18:04.503975Z","iopub.status.busy":"2023-07-21T01:18:04.503205Z","iopub.status.idle":"2023-07-21T01:18:04.510035Z","shell.execute_reply":"2023-07-21T01:18:04.509044Z","shell.execute_reply.started":"2023-07-21T01:18:04.503943Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing get_data.sh\n"]}],"source":["%%writefile get_data.sh\n","mkdir data\n","cd data\n","wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-07-21 11:29:34--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1,1M) [text/plain]\n","Saving to: ‘input.txt’\n","\n","input.txt           100%[===================>]   1,06M  1,09MB/s    in 1,0s    \n","\n","2023-07-21 11:29:35 (1,09 MB/s) - ‘input.txt’ saved [1115394/1115394]\n","\n","get_data.sh: 4: !sh: not found\n"]}],"source":["!sh get_data.sh"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:18:09.880277Z","iopub.status.busy":"2023-07-21T01:18:09.879857Z","iopub.status.idle":"2023-07-21T01:18:11.948771Z","shell.execute_reply":"2023-07-21T01:18:11.947508Z","shell.execute_reply.started":"2023-07-21T01:18:09.880244Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[00:00:00] Pre-processing files (1 Mo)              ░░░░░░░░                  0%\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing files (1 Mo)              ████████                100%\n","[00:00:00] Tokenize words                           ████████ 0        /        0\n","\u001b[2K\u001b[1B\u001b[1A[00:00:00] Tokenize words                           ████████ 13355    /    13355\n","\n","\u001b[2K\u001b[1B\u001b[1A[00:00:00] Count pairs                              ████████ 13355    /    13355\n","\n","\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ░░░░░░░░ 550      /     5000\n","\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ████░░░░ 2700     /     5000\n","\u001b[2K\u001b[1B\u001b[1A[00:00:00] Compute merges                           ████████ 4933     /     4933\n","\n"]}],"source":["!python train_tokenizer.py"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T01:56:36.083189Z","iopub.status.busy":"2023-07-21T01:56:36.082454Z","iopub.status.idle":"2023-07-21T02:42:32.653869Z","shell.execute_reply":"2023-07-21T02:42:32.652271Z","shell.execute_reply.started":"2023-07-21T01:56:36.083152Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Running basic GPT-1 traning on device: 1.\n","Running basic GPT-1 traning on device: 0.\n","Epoch: 0, Training loss: 9.643802960713705\n","Device 1 - Train time: 5.145831153 sec\n","Epoch: 0, Training loss: 9.641467836168077\n","Device 0 - Train time: 5.1693002 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.96it/s]\n","Loss: 12.964556694030762%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 1, Training loss: 9.591565450032553\n","Device 0 - Train time: 4.840364227 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 1, Training loss: 9.594182438320583\n","Device 1 - Train time: 7.929952944 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 12.868279933929443%\n","Epoch: 2, Training loss: 9.527490297953287\n","Device 1 - Train time: 7.585168776 sec\n","Epoch: 2, Training loss: 9.524317741394043\n","Device 0 - Train time: 4.843332298 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 12.757887363433838%\n","Epoch: 3, Training loss: 9.455751948886448\n","Device 1 - Train time: 7.609056067 sec\n","Epoch: 3, Training loss: 9.451320118374294\n","Device 0 - Train time: 4.839759009 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.57it/s]\n","Loss: 12.642696857452393%\n","Epoch: 4, Training loss: 9.38142098320855\n","Device 1 - Train time: 7.625981386 sec\n","Epoch: 4, Training loss: 9.37542724609375\n","Device 0 - Train time: 4.864946411 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.68it/s]\n","Loss: 12.525993347167969%\n","Epoch: 5, Training loss: 9.300103293524849\n","Device 0 - Train time: 4.855962893 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 5, Training loss: 9.305714395311144\n","Device 1 - Train time: 7.614239173 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.37it/s]\n","Loss: 12.40895414352417%\n","Epoch: 6, Training loss: 9.22426086001926\n","Device 0 - Train time: 4.824201181 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 6, Training loss: 9.231444146898058\n","Device 1 - Train time: 7.608399579 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.50it/s]\n","Loss: 12.292037010192871%\n","Epoch: 7, Training loss: 9.156378322177464\n","Device 1 - Train time: 7.619264993 sec\n","Epoch: 7, Training loss: 9.148507118225098\n","Device 0 - Train time: 4.862115681 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.43it/s]\n","Loss: 12.175461769104004%\n","Epoch: 8, Training loss: 9.082177268134224\n","Device 1 - Train time: 7.636952618 sec\n","Epoch: 8, Training loss: 9.073243882921007\n","Device 0 - Train time: 4.881579918 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.63it/s]\n","Loss: 12.0593843460083%\n","Epoch: 9, Training loss: 8.998604032728407\n","Device 0 - Train time: 4.796370432 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 9, Training loss: 9.007800843980577\n","Device 1 - Train time: 7.620181588 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.23it/s]\n","Loss: 11.943963766098022%\n","Epoch: 10, Training loss: 8.923315419091118\n","Device 0 - Train time: 4.850179017 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 10, Training loss: 8.93409898546007\n","Device 1 - Train time: 7.639319017 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.54it/s]\n","Loss: 11.829390048980713%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 11, Training loss: 8.861591868930393\n","Epoch: 11, Training loss: 8.849159823523628\n","Device 0 - Train time: 4.903609879 sec\n","Device 1 - Train time: 8.143739837 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.54it/s]\n","Loss: 11.715916872024536%\n","Epoch: 12, Training loss: 8.788742966122097\n","Device 1 - Train time: 7.624104172 sec\n","Epoch: 12, Training loss: 8.77604145473904\n","Device 0 - Train time: 4.879301491 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.19it/s]\n","Loss: 11.603884935379028%\n","Epoch: 13, Training loss: 8.703613705105251\n","Epoch: 13, Training loss: 8.717932595147026\n","Device 0 - Train time: 4.921467772 sec\n","Device 1 - Train time: 7.742786891 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.52it/s]\n","Loss: 11.493746280670166%\n","Epoch: 14, Training loss: 8.64727889166938\n","Device 1 - Train time: 7.626062747 sec\n","Epoch: 14, Training loss: 8.632649580637613\n","Device 0 - Train time: 4.866209163 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 11.386100769042969%\n","Epoch: 15, Training loss: 8.563777976565891\n","Device 0 - Train time: 4.865645086 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 15, Training loss: 8.579168425665962\n","Device 1 - Train time: 7.675693196 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.48it/s]\n","Loss: 11.281709671020508%\n","Epoch: 16, Training loss: 8.512550301022\n","Device 1 - Train time: 7.583881586 sec\n","Epoch: 16, Training loss: 8.495922883351644\n","Device 0 - Train time: 4.904303804 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.74it/s]\n","Loss: 11.181507110595703%\n","Epoch: 17, Training loss: 8.431690798865425\n","Device 0 - Train time: 4.830308294 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 17, Training loss: 8.449682606591118\n","Device 1 - Train time: 7.646332017 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.62it/s]\n","Loss: 11.086588144302368%\n","Epoch: 18, Training loss: 8.370440748002794\n","Device 0 - Train time: 4.887707668 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 18, Training loss: 8.389006879594591\n","Device 1 - Train time: 7.636969662 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.44it/s]\n","Loss: 10.99809741973877%\n","Epoch: 19, Training loss: 8.31433237923516\n","Epoch: 19, Training loss: 8.332970407274034\n","Device 0 - Train time: 4.903105086 sec\n","Device 1 - Train time: 7.656413444 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.41it/s]\n","Loss: 10.91710352897644%\n","Epoch: 20, Training loss: 8.282620694902208\n","Device 1 - Train time: 7.607846994 sec\n","Epoch: 20, Training loss: 8.262711789872911\n","Device 0 - Train time: 4.83517044 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.52it/s]\n","Loss: 10.844424486160278%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 21, Training loss: 8.216525925530327\n","Device 0 - Train time: 4.84717244 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 21, Training loss: 8.236566437615288\n","Device 1 - Train time: 8.201878249 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.59it/s]\n","Loss: 10.780460596084595%\n","Epoch: 22, Training loss: 8.175375514560276\n","Device 0 - Train time: 4.853997326 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 22, Training loss: 8.195592297448052\n","Device 1 - Train time: 7.595631955 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.39it/s]\n","Loss: 10.725136041641235%\n","Epoch: 23, Training loss: 8.139265643225777\n","Device 0 - Train time: 4.810079084 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 23, Training loss: 8.16111257341173\n","Device 1 - Train time: 7.596605776 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.28it/s]\n","Loss: 10.677919149398804%\n","Epoch: 24, Training loss: 8.130179405212402\n","Device 1 - Train time: 7.581105366 sec\n","Epoch: 24, Training loss: 8.10866477754381\n","Device 0 - Train time: 4.861478259 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.73it/s]\n","Loss: 10.637956380844116%\n","Epoch: 25, Training loss: 8.08247545030382\n","Device 0 - Train time: 4.874683252 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 25, Training loss: 8.10489230685764\n","Device 1 - Train time: 7.660973926 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.99it/s]\n","Loss: 10.60420560836792%\n","Epoch: 26, Training loss: 8.0604035059611\n","Device 0 - Train time: 4.871200161 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 26, Training loss: 8.082554075453016\n","Device 1 - Train time: 7.707115007 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.33it/s]\n","Loss: 10.575628280639648%\n","Epoch: 27, Training loss: 8.041301197475857\n","Device 0 - Train time: 4.827200694 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 27, Training loss: 8.064064237806532\n","Device 1 - Train time: 7.628781545 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.32it/s]\n","Loss: 10.551271438598633%\n","Epoch: 28, Training loss: 8.025067700280083\n","Epoch: 28, Training loss: 8.047515763176811\n","Device 0 - Train time: 4.841935546 sec\n","Device 1 - Train time: 7.605654781 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.55it/s]\n","Loss: 10.530307054519653%\n","Epoch: 29, Training loss: 8.010146035088432\n","Device 0 - Train time: 4.91022922 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 29, Training loss: 8.033029132419163\n","Device 1 - Train time: 7.673727911 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.33it/s]\n","Loss: 10.512054443359375%\n","Epoch: 30, Training loss: 7.997254212697347\n","Epoch: 30, Training loss: 8.020786762237549\n","Device 0 - Train time: 4.824623954 sec\n","Device 1 - Train time: 7.610573027 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.60it/s]\n","Loss: 10.495966911315918%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 31, Training loss: 8.010016388363308\n","Device 1 - Train time: 8.149053794 sec\n","Epoch: 31, Training loss: 7.986573537190755\n","Device 0 - Train time: 4.885798303 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.71it/s]\n","Loss: 10.481607913970947%\n","Epoch: 32, Training loss: 7.976834138234456\n","Device 0 - Train time: 4.839324444 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 32, Training loss: 7.999702824486627\n","Device 1 - Train time: 7.621448084 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 10.46863079071045%\n","Epoch: 33, Training loss: 7.966972457038032\n","Device 0 - Train time: 4.843805267 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 33, Training loss: 7.9903782738579645\n","Device 1 - Train time: 7.613406769 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.57it/s]\n","Loss: 10.45677137374878%\n","Epoch: 34, Training loss: 7.959411091274685\n","Device 0 - Train time: 4.896694118 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 34, Training loss: 7.982205708821614\n","Device 1 - Train time: 7.621540177 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.48it/s]\n","Loss: 10.44581913948059%\n","Epoch: 35, Training loss: 7.973924371931288\n","Device 1 - Train time: 7.661823332 sec\n","Epoch: 35, Training loss: 7.951126310560438\n","Device 0 - Train time: 4.904596987 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.73it/s]\n","Loss: 10.435609340667725%\n","Epoch: 36, Training loss: 7.943343374464247\n","Device 0 - Train time: 4.873769289 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 36, Training loss: 7.966484175788032\n","Device 1 - Train time: 7.633289947 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.11it/s]\n","Loss: 10.426011085510254%\n","Epoch: 37, Training loss: 7.9362550841437445\n","Device 0 - Train time: 4.846945956 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 37, Training loss: 7.959611468844944\n","Device 1 - Train time: 7.664906752 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.53it/s]\n","Loss: 10.416920185089111%\n","Epoch: 38, Training loss: 7.953204737769233\n","Device 1 - Train time: 7.660105913 sec\n","Epoch: 38, Training loss: 7.929982821146647\n","Device 0 - Train time: 4.910361824 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.40it/s]\n","Loss: 10.408254861831665%\n","Epoch: 39, Training loss: 7.923339737786187\n","Device 0 - Train time: 4.913814735 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 39, Training loss: 7.947102440728082\n","Device 1 - Train time: 7.713573049 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.36it/s]\n","Loss: 10.399945735931396%\n","Epoch: 40, Training loss: 7.91738043891059\n","Device 0 - Train time: 4.839917545 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 40, Training loss: 7.941118823157416\n","Device 1 - Train time: 7.648356187 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.27it/s]\n","Loss: 10.391938924789429%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 41, Training loss: 7.911213450961643\n","Device 0 - Train time: 4.871049947 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 41, Training loss: 7.93540440665351\n","Device 1 - Train time: 8.130102711 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.40it/s]\n","Loss: 10.384186029434204%\n","Epoch: 42, Training loss: 7.906608475579156\n","Device 0 - Train time: 4.896380235 sec\n","Epoch: 42, Training loss: 7.929534223344591\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Device 1 - Train time: 7.671728081 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.18it/s]\n","Loss: 10.376652479171753%\n","Epoch: 43, Training loss: 7.900464958614773\n","Device 0 - Train time: 4.916799546 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 43, Training loss: 7.924138493008083\n","Device 1 - Train time: 7.729584731 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 10.369305849075317%\n","Epoch: 44, Training loss: 7.894643995496962\n","Device 0 - Train time: 4.896187597 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 44, Training loss: 7.917653719584147\n","Device 1 - Train time: 7.659700397 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.91it/s]\n","Loss: 10.362121820449829%\n","Epoch: 45, Training loss: 7.912804338667128\n","Device 1 - Train time: 7.700807488 sec\n","Epoch: 45, Training loss: 7.889458974202474\n","Device 0 - Train time: 4.880227561 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.67it/s]\n","Loss: 10.355075120925903%\n","Epoch: 46, Training loss: 7.908197826809353\n","Device 1 - Train time: 7.662313711 sec\n","Epoch: 46, Training loss: 7.884569962819417\n","Device 0 - Train time: 4.906333922 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.45it/s]\n","Loss: 10.348150491714478%\n","Epoch: 47, Training loss: 7.879087448120117\n","Device 0 - Train time: 4.918504032 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 47, Training loss: 7.902889993455675\n","Device 1 - Train time: 7.711253676 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.24it/s]\n","Loss: 10.341330289840698%\n","Epoch: 48, Training loss: 7.874758243560791\n","Device 0 - Train time: 4.818654557 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 48, Training loss: 7.8975497881571455\n","Device 1 - Train time: 7.645305647 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.33it/s]\n","Loss: 10.33459997177124%\n","Epoch: 49, Training loss: 7.8931313090854225\n","Device 1 - Train time: 7.631421596 sec\n","Epoch: 49, Training loss: 7.868993229336208\n","Device 0 - Train time: 4.890883153 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.41it/s]\n","Loss: 10.32794737815857%\n","Epoch: 50, Training loss: 7.864327059851752\n","Device 0 - Train time: 4.900973167 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 50, Training loss: 7.887816217210558\n","Device 1 - Train time: 7.6949108 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.40it/s]\n","Loss: 10.321364641189575%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 51, Training loss: 7.8591844240824384\n","Device 0 - Train time: 4.882977359 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 51, Training loss: 7.883208168877496\n","Device 1 - Train time: 8.182795607 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.66it/s]\n","Loss: 10.31484079360962%\n","Epoch: 52, Training loss: 7.8782434993320045\n","Device 1 - Train time: 7.621383438 sec\n","Epoch: 52, Training loss: 7.854207780626085\n","Device 0 - Train time: 4.882806072 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.47it/s]\n","Loss: 10.308368444442749%\n","Epoch: 53, Training loss: 7.849742041693793\n","Device 0 - Train time: 4.86730102 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 53, Training loss: 7.873687320285374\n","Device 1 - Train time: 7.646693457 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.27it/s]\n","Loss: 10.301939487457275%\n","Epoch: 54, Training loss: 7.868749141693115\n","Device 1 - Train time: 7.612043943 sec\n","Epoch: 54, Training loss: 7.844882488250732\n","Device 0 - Train time: 4.857556097 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.59it/s]\n","Loss: 10.295550346374512%\n","Epoch: 55, Training loss: 7.864203188154432\n","Device 1 - Train time: 7.703540809 sec\n","Epoch: 55, Training loss: 7.840558422936334\n","Device 0 - Train time: 4.912627138 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.28it/s]\n","Loss: 10.289194107055664%\n","Epoch: 56, Training loss: 7.8594895998636884\n","Device 1 - Train time: 7.622401621 sec\n","Epoch: 56, Training loss: 7.836034986707899\n","Device 0 - Train time: 4.83909063 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.57it/s]\n","Loss: 10.282865524291992%\n","Epoch: 57, Training loss: 7.854733361138238\n","Device 1 - Train time: 7.602085828 sec\n","Epoch: 57, Training loss: 7.831399122873942\n","Device 0 - Train time: 4.852344487 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.54it/s]\n","Loss: 10.276559591293335%\n","Epoch: 58, Training loss: 7.826985041300456\n","Device 0 - Train time: 4.843268413 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 58, Training loss: 7.85056045320299\n","Device 1 - Train time: 7.65612142 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.22it/s]\n","Loss: 10.270273685455322%\n","Epoch: 59, Training loss: 7.821293671925862\n","Device 0 - Train time: 4.829691486 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 59, Training loss: 7.845406108432346\n","Device 1 - Train time: 7.633511447 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.98it/s]\n","Loss: 10.26400351524353%\n","Epoch: 60, Training loss: 7.840872605641683\n","Device 1 - Train time: 7.641069113 sec\n","Epoch: 60, Training loss: 7.81625509262085\n","Device 0 - Train time: 4.853892122 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.61it/s]\n","Loss: 10.257748365402222%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 61, Training loss: 7.836210197872585\n","Device 1 - Train time: 8.163912637 sec\n","Epoch: 61, Training loss: 7.81245666080051\n","Device 0 - Train time: 4.901878521 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.82it/s]\n","Loss: 10.251502275466919%\n","Epoch: 62, Training loss: 7.807742065853542\n","Epoch: 62, Training loss: 7.831678973303901\n","Device 0 - Train time: 4.85238999 sec\n","Device 1 - Train time: 7.597375353 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 10.245262622833252%\n","Epoch: 63, Training loss: 7.803522004021539\n","Device 0 - Train time: 4.874307136 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 63, Training loss: 7.827361848619249\n","Device 1 - Train time: 7.67674683 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.49it/s]\n","Loss: 10.2390296459198%\n","Epoch: 64, Training loss: 7.798491583930121\n","Device 0 - Train time: 4.857121319 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 64, Training loss: 7.822495990329319\n","Device 1 - Train time: 7.601709067 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.81it/s]\n","Loss: 10.232800483703613%\n","Epoch: 65, Training loss: 7.794755988650852\n","Device 0 - Train time: 4.868910132 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 65, Training loss: 7.818224165174696\n","Device 1 - Train time: 7.716331032 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.64it/s]\n","Loss: 10.22657060623169%\n","Epoch: 66, Training loss: 7.8134397930569115\n","Device 1 - Train time: 7.592655669 sec\n","Epoch: 66, Training loss: 7.789376629723443\n","Device 0 - Train time: 4.857569543 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.49it/s]\n","Loss: 10.220340490341187%\n","Epoch: 67, Training loss: 7.784788873460558\n","Device 0 - Train time: 4.878442388 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 67, Training loss: 7.808576001061334\n","Device 1 - Train time: 7.686219058 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.54it/s]\n","Loss: 10.214107751846313%\n","Epoch: 68, Training loss: 7.803919633229573\n","Device 1 - Train time: 7.595288148 sec\n","Epoch: 68, Training loss: 7.780167049831814\n","Device 0 - Train time: 4.876801999 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.68it/s]\n","Loss: 10.207870960235596%\n","Epoch: 69, Training loss: 7.799301465352376\n","Device 1 - Train time: 7.577202691 sec\n","Epoch: 69, Training loss: 7.776063389248318\n","Device 0 - Train time: 4.862970783 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.47it/s]\n","Loss: 10.201627492904663%\n","Epoch: 70, Training loss: 7.794681972927517\n","Device 1 - Train time: 7.682694892 sec\n","Epoch: 70, Training loss: 7.771076997121175\n","Device 0 - Train time: 4.884467379 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 10.195376634597778%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 71, Training loss: 7.766700426737468\n","Device 0 - Train time: 4.82875071 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 71, Training loss: 7.7903510729471845\n","Device 1 - Train time: 8.175817902 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.54it/s]\n","Loss: 10.18911862373352%\n","Epoch: 72, Training loss: 7.761492729187012\n","Device 0 - Train time: 4.8529418 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 72, Training loss: 7.785890261332194\n","Device 1 - Train time: 7.596627301 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.28it/s]\n","Loss: 10.18285322189331%\n","Epoch: 73, Training loss: 7.756952232784695\n","Device 0 - Train time: 4.810892174 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 73, Training loss: 7.781224780612522\n","Device 1 - Train time: 7.613595423 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.39it/s]\n","Loss: 10.176574945449829%\n","Epoch: 74, Training loss: 7.776601685418023\n","Device 1 - Train time: 7.652670288 sec\n","Epoch: 74, Training loss: 7.752712514665392\n","Device 0 - Train time: 4.915332966 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.73it/s]\n","Loss: 10.17028546333313%\n","Epoch: 75, Training loss: 7.748107804192437\n","Epoch: 75, Training loss: 7.771665785047743\n","Device 0 - Train time: 4.848228632 sec\n","Device 1 - Train time: 7.596764473 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.18it/s]\n","Loss: 10.16398286819458%\n","Epoch: 76, Training loss: 7.767282909817165\n","Device 1 - Train time: 7.660874856 sec\n","Epoch: 76, Training loss: 7.7437741491529675\n","Device 0 - Train time: 4.877002911 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.78it/s]\n","Loss: 10.157667398452759%\n","Epoch: 77, Training loss: 7.738469017876519\n","Device 0 - Train time: 4.847108549 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 77, Training loss: 7.762431886461046\n","Device 1 - Train time: 7.607496505 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.48it/s]\n","Loss: 10.151334762573242%\n","Epoch: 78, Training loss: 7.757867548200819\n","Device 1 - Train time: 7.601536295 sec\n","Epoch: 78, Training loss: 7.7340282864040795\n","Device 0 - Train time: 4.838514407 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.60it/s]\n","Loss: 10.144989490509033%\n","Epoch: 79, Training loss: 7.7292238341437445\n","Device 0 - Train time: 4.903151231 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 79, Training loss: 7.7533482975429955\n","Device 1 - Train time: 7.675526486 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.30it/s]\n","Loss: 10.138627767562866%\n","Epoch: 80, Training loss: 7.748170693715413\n","Device 1 - Train time: 7.629185337 sec\n","Epoch: 80, Training loss: 7.724387804667155\n","Device 0 - Train time: 4.867429025 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.72it/s]\n","Loss: 10.132250308990479%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 81, Training loss: 7.744010501437717\n","Device 1 - Train time: 8.154320956 sec\n","Epoch: 81, Training loss: 7.7199135356479225\n","Device 0 - Train time: 4.869588085 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.23it/s]\n","Loss: 10.125854253768921%\n","Epoch: 82, Training loss: 7.715398417578803\n","Device 0 - Train time: 4.891807646 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 82, Training loss: 7.739147027333577\n","Device 1 - Train time: 7.707658614 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.43it/s]\n","Loss: 10.119439363479614%\n","Epoch: 83, Training loss: 7.710505697462294\n","Device 0 - Train time: 4.84452659 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 83, Training loss: 7.734043916066487\n","Device 1 - Train time: 7.647443843 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.84it/s]\n","Loss: 10.113008737564087%\n","Epoch: 84, Training loss: 7.72965939839681\n","Device 1 - Train time: 7.677189333 sec\n","Epoch: 84, Training loss: 7.705562909444173\n","Device 0 - Train time: 4.874045683 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 10.106555700302124%\n","Epoch: 85, Training loss: 7.724660767449273\n","Device 1 - Train time: 7.636148509 sec\n","Epoch: 85, Training loss: 7.7007472780015735\n","Device 0 - Train time: 4.877132262 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.63it/s]\n","Loss: 10.100086450576782%\n","Epoch: 86, Training loss: 7.720040798187256\n","Device 1 - Train time: 7.623965598 sec\n","Epoch: 86, Training loss: 7.696076234181722\n","Device 0 - Train time: 4.877246401 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.20it/s]\n","Loss: 10.093595743179321%\n","Epoch: 87, Training loss: 7.715138064490424\n","Device 1 - Train time: 7.684687532 sec\n","Epoch: 87, Training loss: 7.6913132137722435\n","Device 0 - Train time: 4.870972387 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.72it/s]\n","Loss: 10.08708643913269%\n","Epoch: 88, Training loss: 7.710852040184869\n","Device 1 - Train time: 7.651890433 sec\n","Epoch: 88, Training loss: 7.686968114640978\n","Device 0 - Train time: 4.922628111 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.81it/s]\n","Loss: 10.080554962158203%\n","Epoch: 89, Training loss: 7.682183371649848\n","Device 0 - Train time: 4.826878237 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 89, Training loss: 7.706163247426351\n","Device 1 - Train time: 7.621071854 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.43it/s]\n","Loss: 10.074002027511597%\n","Epoch: 90, Training loss: 7.677104261186388\n","Device 0 - Train time: 4.898884234 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 90, Training loss: 7.7007102436489525\n","Device 1 - Train time: 7.638337544 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.98it/s]\n","Loss: 10.067426204681396%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 91, Training loss: 7.672723452250163\n","Device 0 - Train time: 4.866795118 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 91, Training loss: 7.6967788802252874\n","Device 1 - Train time: 8.213240636 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.53it/s]\n","Loss: 10.060829877853394%\n","Epoch: 92, Training loss: 7.691685093773736\n","Device 1 - Train time: 7.572743935 sec\n","Epoch: 92, Training loss: 7.667264408535427\n","Device 0 - Train time: 4.874437484 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.91it/s]\n","Loss: 10.054211378097534%\n","Epoch: 93, Training loss: 7.661927223205566\n","Device 0 - Train time: 4.871077809 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 93, Training loss: 7.686919477250841\n","Device 1 - Train time: 7.645701013 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.98it/s]\n","Loss: 10.047570705413818%\n","Epoch: 94, Training loss: 7.657574653625488\n","Device 0 - Train time: 4.870822771 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 94, Training loss: 7.6816175778706866\n","Device 1 - Train time: 7.700809431 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.31it/s]\n","Loss: 10.04090690612793%\n","Epoch: 95, Training loss: 7.676681995391846\n","Device 1 - Train time: 7.606150498 sec\n","Epoch: 95, Training loss: 7.652903450859918\n","Device 0 - Train time: 4.876203913 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.83it/s]\n","Loss: 10.034219741821289%\n","Epoch: 96, Training loss: 7.647921138339573\n","Device 0 - Train time: 4.909373187 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 96, Training loss: 7.671713829040527\n","Device 1 - Train time: 7.820483702 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.23it/s]\n","Loss: 10.027510166168213%\n","Epoch: 97, Training loss: 7.666949537065294\n","Device 1 - Train time: 7.681715536 sec\n","Epoch: 97, Training loss: 7.643201986948649\n","Device 0 - Train time: 4.895716981 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.54it/s]\n","Loss: 10.020777225494385%\n","Epoch: 98, Training loss: 7.661656008826362\n","Device 1 - Train time: 7.663777352 sec\n","Epoch: 98, Training loss: 7.638088438245985\n","Device 0 - Train time: 4.901897369 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.64it/s]\n","Loss: 10.014021396636963%\n","Epoch: 99, Training loss: 7.632819493611653\n","Device 0 - Train time: 4.847854293 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 99, Training loss: 7.657219780815972\n","Device 1 - Train time: 7.607304035 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.60it/s]\n","Loss: 10.007244348526001%\n","Epoch: 100, Training loss: 7.627716912163629\n","Device 0 - Train time: 4.84248177 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 100, Training loss: 7.651765505472819\n","Device 1 - Train time: 7.631657584 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.49it/s]\n","Loss: 10.00044298171997%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 101, Training loss: 7.6494855880737305\n","Epoch: 101, Training loss: 7.625045935312907\n","Device 1 - Train time: 8.146511665 sec\n","Device 0 - Train time: 4.898051028 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.36it/s]\n","Loss: 9.999762773513794%\n","Epoch: 102, Training loss: 7.64856481552124\n","Device 1 - Train time: 7.639926136 sec\n","Epoch: 102, Training loss: 7.624217298295763\n","Device 0 - Train time: 4.857744122 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.80it/s]\n","Loss: 9.999083280563354%\n","Epoch: 103, Training loss: 7.6477245224846735\n","Device 1 - Train time: 7.664864331 sec\n","Epoch: 103, Training loss: 7.624029901292589\n","Device 0 - Train time: 4.863132434 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.92it/s]\n","Loss: 9.998402118682861%\n","Epoch: 104, Training loss: 7.647566477457683\n","Device 1 - Train time: 7.60618441 sec\n","Epoch: 104, Training loss: 7.623604509565565\n","Device 0 - Train time: 4.870701032 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.83it/s]\n","Loss: 9.997721910476685%\n","Epoch: 105, Training loss: 7.6472464137607155\n","Device 1 - Train time: 7.644023286 sec\n","Epoch: 105, Training loss: 7.623983171251085\n","Device 0 - Train time: 4.891210914 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.997040271759033%\n","Epoch: 106, Training loss: 7.622478644053142\n","Device 0 - Train time: 4.830210829 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 106, Training loss: 7.646603266398112\n","Device 1 - Train time: 7.641900585 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.48it/s]\n","Loss: 9.996359825134277%\n","Epoch: 107, Training loss: 7.6221316125657825\n","Device 0 - Train time: 4.862354385 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 107, Training loss: 7.646316104465061\n","Device 1 - Train time: 7.605518716 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.18it/s]\n","Loss: 9.995678901672363%\n","Epoch: 108, Training loss: 7.645512474907769\n","Device 1 - Train time: 7.652678858 sec\n","Epoch: 108, Training loss: 7.621343824598524\n","Device 0 - Train time: 4.856673586 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.72it/s]\n","Loss: 9.994996309280396%\n","Epoch: 109, Training loss: 7.620626078711616\n","Device 0 - Train time: 4.819943982 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 109, Training loss: 7.645179324679905\n","Device 1 - Train time: 7.602800735 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.10it/s]\n","Loss: 9.994316339492798%\n","Epoch: 110, Training loss: 7.644448068406847\n","Device 1 - Train time: 7.643097783 sec\n","Epoch: 110, Training loss: 7.620702690548367\n","Device 0 - Train time: 4.86666438 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.64it/s]\n","Loss: 9.993633508682251%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 111, Training loss: 7.620013078053792\n","Device 0 - Train time: 4.847838896 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 111, Training loss: 7.6444382137722435\n","Device 1 - Train time: 8.119936041 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.64it/s]\n","Loss: 9.992950916290283%\n","Epoch: 112, Training loss: 7.620427926381429\n","Device 0 - Train time: 4.867045516 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 112, Training loss: 7.644010225931804\n","Device 1 - Train time: 7.660490809 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.41it/s]\n","Loss: 9.992268323898315%\n","Epoch: 113, Training loss: 7.642764727274577\n","Device 1 - Train time: 7.593638968 sec\n","Epoch: 113, Training loss: 7.619508107503255\n","Device 0 - Train time: 4.867921227 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.82it/s]\n","Loss: 9.99158501625061%\n","Epoch: 114, Training loss: 7.642231782277425\n","Device 1 - Train time: 7.570020577 sec\n","Epoch: 114, Training loss: 7.618706650204128\n","Device 0 - Train time: 4.870400755 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.78it/s]\n","Loss: 9.990902662277222%\n","Epoch: 115, Training loss: 7.61782349480523\n","Device 0 - Train time: 4.856668 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 115, Training loss: 7.641937255859375\n","Device 1 - Train time: 7.674589607 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.990217924118042%\n","Epoch: 116, Training loss: 7.6412895520528155\n","Device 1 - Train time: 7.54953441 sec\n","Epoch: 116, Training loss: 7.617229567633735\n","Device 0 - Train time: 4.841148567 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.46it/s]\n","Loss: 9.989535808563232%\n","Epoch: 117, Training loss: 7.641442404852973\n","Device 1 - Train time: 7.645754979 sec\n","Epoch: 117, Training loss: 7.617118835449219\n","Device 0 - Train time: 4.866650295 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.99it/s]\n","Loss: 9.98885202407837%\n","Epoch: 118, Training loss: 7.640286021762424\n","Device 1 - Train time: 7.712520551 sec\n","Epoch: 118, Training loss: 7.616909715864393\n","Device 0 - Train time: 4.893688451 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.66it/s]\n","Loss: 9.988168001174927%\n","Epoch: 119, Training loss: 7.616548856099446\n","Device 0 - Train time: 4.842915546 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 119, Training loss: 7.639635350969103\n","Device 1 - Train time: 7.636379349 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.46it/s]\n","Loss: 9.987483501434326%\n","Epoch: 120, Training loss: 7.639265749189589\n","Device 1 - Train time: 7.61444122 sec\n","Epoch: 120, Training loss: 7.616074932946099\n","Device 0 - Train time: 4.888923873 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.60it/s]\n","Loss: 9.986800909042358%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 121, Training loss: 7.614728662702772\n","Epoch: 121, Training loss: 7.638725492689344\n","Device 0 - Train time: 4.898266893 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Device 1 - Train time: 8.181241137 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.47it/s]\n","Loss: 9.9861159324646%\n","Epoch: 122, Training loss: 7.638387521107991\n","Device 1 - Train time: 7.680088053 sec\n","Epoch: 122, Training loss: 7.614134629567464\n","Device 0 - Train time: 4.911430999 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.98543095588684%\n","Epoch: 123, Training loss: 7.638256390889485\n","Device 1 - Train time: 7.652633191 sec\n","Epoch: 123, Training loss: 7.6137147479587135\n","Device 0 - Train time: 4.889385548 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.54it/s]\n","Loss: 9.984745502471924%\n","Epoch: 124, Training loss: 7.637545214758979\n","Device 1 - Train time: 7.568190574 sec\n","Epoch: 124, Training loss: 7.6136208110385475\n","Device 0 - Train time: 4.804039008 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.91it/s]\n","Loss: 9.984060525894165%\n","Epoch: 125, Training loss: 7.613212691413032\n","Device 0 - Train time: 4.863440481 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 125, Training loss: 7.6368895636664496\n","Device 1 - Train time: 7.712478069 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.67it/s]\n","Loss: 9.983375549316406%\n","Epoch: 126, Training loss: 7.63699287838406\n","Device 1 - Train time: 7.586503032 sec\n","Epoch: 126, Training loss: 7.6121517817179365\n","Device 0 - Train time: 4.878579386 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.78it/s]\n","Loss: 9.982688665390015%\n","Epoch: 127, Training loss: 7.611880249447292\n","Device 0 - Train time: 4.847509318 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 127, Training loss: 7.63482469982571\n","Device 1 - Train time: 7.623065174 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.98200249671936%\n","Epoch: 128, Training loss: 7.6113547219170465\n","Device 0 - Train time: 4.825968958 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 128, Training loss: 7.635225613911946\n","Device 1 - Train time: 7.615000036 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.36it/s]\n","Loss: 9.981315612792969%\n","Epoch: 129, Training loss: 7.634929656982422\n","Device 1 - Train time: 7.652632809 sec\n","Epoch: 129, Training loss: 7.6101442442999945\n","Device 0 - Train time: 4.900607613 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.38it/s]\n","Loss: 9.980629920959473%\n","Epoch: 130, Training loss: 7.6106127632988825\n","Device 0 - Train time: 4.864604317 sec\n","Epoch: 130, Training loss: 7.634127669864231\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Device 1 - Train time: 7.648993433 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.22it/s]\n","Loss: 9.979943990707397%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 131, Training loss: 7.61006498336792\n","Device 0 - Train time: 4.83539881 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 131, Training loss: 7.634247938791911\n","Device 1 - Train time: 8.198461171 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.60it/s]\n","Loss: 9.979257583618164%\n","Epoch: 132, Training loss: 7.609446419609918\n","Device 0 - Train time: 4.899524226 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 132, Training loss: 7.633636050754124\n","Device 1 - Train time: 7.62830331 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.45it/s]\n","Loss: 9.978569984436035%\n","Epoch: 133, Training loss: 7.608877129024929\n","Device 0 - Train time: 4.83080356 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 133, Training loss: 7.632505628797743\n","Device 1 - Train time: 7.616378299 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.30it/s]\n","Loss: 9.977882623672485%\n","Epoch: 134, Training loss: 7.609020974900988\n","Device 0 - Train time: 4.861287407 sec\n","Epoch: 134, Training loss: 7.632582558525933\n","Device 1 - Train time: 7.629584063 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.50it/s]\n","Loss: 9.977194786071777%\n","Epoch: 135, Training loss: 7.6081504291958275\n","Device 0 - Train time: 4.903142978 sec\n","Epoch: 135, Training loss: 7.631470256381565\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Device 1 - Train time: 7.671808012 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.16it/s]\n","Loss: 9.97650671005249%\n","Epoch: 136, Training loss: 7.631789260440403\n","Device 1 - Train time: 7.701247738 sec\n","Epoch: 136, Training loss: 7.607284333970812\n","Device 0 - Train time: 4.91001231 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.97581934928894%\n","Epoch: 137, Training loss: 7.631375577714708\n","Device 1 - Train time: 7.645798673 sec\n","Epoch: 137, Training loss: 7.606514083014594\n","Device 0 - Train time: 4.907057409 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.58it/s]\n","Loss: 9.975130558013916%\n","Epoch: 138, Training loss: 7.630652745564778\n","Device 1 - Train time: 7.598340726 sec\n","Epoch: 138, Training loss: 7.607169734107123\n","Device 0 - Train time: 4.847636041 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.68it/s]\n","Loss: 9.97444200515747%\n","Epoch: 139, Training loss: 7.62931309805976\n","Epoch: 139, Training loss: 7.606285783979628\n","Device 1 - Train time: 7.678027593 sec\n","Device 0 - Train time: 4.883822469 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.29it/s]\n","Loss: 9.973752975463867%\n","Epoch: 140, Training loss: 7.6056210199991865\n","Device 0 - Train time: 4.863560516 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 140, Training loss: 7.629162894354926\n","Device 1 - Train time: 7.669278086 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.42it/s]\n","Loss: 9.973064661026001%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 141, Training loss: 7.604819827609592\n","Device 0 - Train time: 4.90204633 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 141, Training loss: 7.62880187564426\n","Device 1 - Train time: 8.189551602 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.972373962402344%\n","Epoch: 142, Training loss: 7.604299704233806\n","Device 0 - Train time: 4.825653288 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 142, Training loss: 7.628175735473633\n","Device 1 - Train time: 7.614405303 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.98it/s]\n","Loss: 9.971685886383057%\n","Epoch: 143, Training loss: 7.603981388939752\n","Device 0 - Train time: 4.834665062 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 143, Training loss: 7.628131866455078\n","Device 1 - Train time: 7.677226955 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.15it/s]\n","Loss: 9.970995426177979%\n","Epoch: 144, Training loss: 7.627439975738525\n","Device 1 - Train time: 7.643838297 sec\n","Epoch: 144, Training loss: 7.603209389580621\n","Device 0 - Train time: 4.893501103 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.47it/s]\n","Loss: 9.97030520439148%\n","Epoch: 145, Training loss: 7.603166262308757\n","Device 0 - Train time: 4.877617449 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 145, Training loss: 7.626723925272624\n","Device 1 - Train time: 7.660248045 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.48it/s]\n","Loss: 9.969615936279297%\n","Epoch: 146, Training loss: 7.602716128031413\n","Device 0 - Train time: 4.869329736 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 146, Training loss: 7.626382827758789\n","Device 1 - Train time: 7.654015659 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.22it/s]\n","Loss: 9.96892499923706%\n","Epoch: 147, Training loss: 7.625903765360515\n","Device 1 - Train time: 7.656947487 sec\n","Epoch: 147, Training loss: 7.602208561367458\n","Device 0 - Train time: 4.885214314 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.19it/s]\n","Loss: 9.968234777450562%\n","Epoch: 148, Training loss: 7.625147024790446\n","Device 1 - Train time: 7.668061399 sec\n","Epoch: 148, Training loss: 7.601396984524197\n","Device 0 - Train time: 4.873057463 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.25it/s]\n","Loss: 9.967543363571167%\n","Epoch: 149, Training loss: 7.600778049892849\n","Device 0 - Train time: 4.828392234 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 149, Training loss: 7.62492561340332\n","Device 1 - Train time: 7.699441367 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.03it/s]\n","Loss: 9.96685242652893%\n","Epoch: 150, Training loss: 7.624686400095622\n","Device 1 - Train time: 7.675662316 sec\n","Epoch: 150, Training loss: 7.600561406877306\n","Device 0 - Train time: 4.923902564 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.72it/s]\n","Loss: 9.966161251068115%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 151, Training loss: 7.6241224606831866\n","Device 1 - Train time: 8.161235458 sec\n","Epoch: 151, Training loss: 7.59987227121989\n","Device 0 - Train time: 4.888008542 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.61it/s]\n","Loss: 9.966099739074707%\n","Epoch: 152, Training loss: 7.624003145429823\n","Device 1 - Train time: 7.61781015 sec\n","Epoch: 152, Training loss: 7.599883609347874\n","Device 0 - Train time: 4.864353914 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.68it/s]\n","Loss: 9.966036319732666%\n","Epoch: 153, Training loss: 7.599936803181966\n","Device 0 - Train time: 4.899822265 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 153, Training loss: 7.623953501383464\n","Device 1 - Train time: 7.654119025 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.64it/s]\n","Loss: 9.965973377227783%\n","Epoch: 154, Training loss: 7.624012682172987\n","Device 1 - Train time: 7.59473792 sec\n","Epoch: 154, Training loss: 7.60006856918335\n","Device 0 - Train time: 4.851646415 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.23it/s]\n","Loss: 9.965911388397217%\n","Epoch: 155, Training loss: 7.599513477749294\n","Epoch: 155, Training loss: 7.623425642649333\n","Device 0 - Train time: 4.879349935 sec\n","Device 1 - Train time: 7.681734306 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.41it/s]\n","Loss: 9.965848207473755%\n","Epoch: 156, Training loss: 7.600178241729736\n","Epoch: 156, Training loss: 7.623552004496257\n","Device 0 - Train time: 4.875446232 sec\n","Device 1 - Train time: 7.654618188 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.96578574180603%\n","Epoch: 157, Training loss: 7.5996772978040905\n","Device 0 - Train time: 4.820208275 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 157, Training loss: 7.6237364874945746\n","Device 1 - Train time: 7.628386274 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.31it/s]\n","Loss: 9.965723276138306%\n","Epoch: 158, Training loss: 7.599705166286892\n","Device 0 - Train time: 4.901031557 sec\n","Epoch: 158, Training loss: 7.6241984367370605\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Device 1 - Train time: 7.650216544 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.46it/s]\n","Loss: 9.96566128730774%\n","Epoch: 159, Training loss: 7.599652396308051\n","Device 0 - Train time: 4.836639515 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 159, Training loss: 7.6237329377068415\n","Device 1 - Train time: 7.639806318 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.41it/s]\n","Loss: 9.96559762954712%\n","Epoch: 160, Training loss: 7.599404017130534\n","Device 0 - Train time: 4.866084016 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 160, Training loss: 7.623346116807726\n","Device 1 - Train time: 7.619574608 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.46it/s]\n","Loss: 9.965535163879395%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 161, Training loss: 7.599792904324001\n","Device 0 - Train time: 4.850712755 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 161, Training loss: 7.623426119486491\n","Device 1 - Train time: 8.189502687 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.32it/s]\n","Loss: 9.965471982955933%\n","Epoch: 162, Training loss: 7.624231126573351\n","Device 1 - Train time: 7.623050889 sec\n","Epoch: 162, Training loss: 7.598976029290093\n","Device 0 - Train time: 4.885939449 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.46it/s]\n","Loss: 9.96540880203247%\n","Epoch: 163, Training loss: 7.623407310909695\n","Device 1 - Train time: 7.66801129 sec\n","Epoch: 163, Training loss: 7.5996204482184515\n","Device 0 - Train time: 4.89341844 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.36it/s]\n","Loss: 9.965347051620483%\n","Epoch: 164, Training loss: 7.599921862284343Epoch: 164, Training loss: 7.623246457841661\n","\n","Device 0 - Train time: 4.863380029 sec\n","Device 1 - Train time: 7.65372851 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.49it/s]\n","Loss: 9.9652841091156%\n","Epoch: 165, Training loss: 7.623536745707194Epoch: 165, Training loss: 7.6001865069071455\n","\n","Device 0 - Train time: 4.909569141 sec\n","Device 1 - Train time: 7.679030001 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.95it/s]\n","Loss: 9.965221166610718%\n","Epoch: 166, Training loss: 7.623195224338108\n","Device 1 - Train time: 7.704962286 sec\n","Epoch: 166, Training loss: 7.599051528506809\n","Device 0 - Train time: 4.903816816 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.53it/s]\n","Loss: 9.965159893035889%\n","Epoch: 167, Training loss: 7.599326133728027\n","Device 0 - Train time: 4.872843833 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 167, Training loss: 7.623151514265272\n","Device 1 - Train time: 7.671194679 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.57it/s]\n","Loss: 9.96509575843811%\n","Epoch: 168, Training loss: 7.623467657301161\n","Epoch: 168, Training loss: 7.599354796939426\n","Device 0 - Train time: 4.850355926 sec\n","Device 1 - Train time: 7.606043359 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.47it/s]\n","Loss: 9.965033292770386%\n","Epoch: 169, Training loss: 7.623111936781141\n","Device 1 - Train time: 7.608463184 sec\n","Epoch: 169, Training loss: 7.599303616417779\n","Device 0 - Train time: 4.848417404 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.23it/s]\n","Loss: 9.964970588684082%\n","Epoch: 170, Training loss: 7.623293929629856\n","Epoch: 170, Training loss: 7.59963411755032\n","Device 1 - Train time: 7.658482003 sec\n","Device 0 - Train time: 4.848015972 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.48it/s]\n","Loss: 9.964907884597778%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 171, Training loss: 7.599351459079319\n","Device 0 - Train time: 4.896013474 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 171, Training loss: 7.622972276475695\n","Device 1 - Train time: 8.195456347 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.22it/s]\n","Loss: 9.964844942092896%\n","Epoch: 172, Training loss: 7.598862171173096\n","Device 0 - Train time: 4.830857978 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 172, Training loss: 7.62254015604655\n","Device 1 - Train time: 7.655726232 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.29it/s]\n","Loss: 9.964782238006592%\n","Epoch: 173, Training loss: 7.599010467529297\n","Device 0 - Train time: 4.861363521 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 173, Training loss: 7.622915320926243\n","Device 1 - Train time: 7.655537875 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.36it/s]\n","Loss: 9.964720249176025%\n","Epoch: 174, Training loss: 7.623415523105198\n","Device 1 - Train time: 7.634961792 sec\n","Epoch: 174, Training loss: 7.599059687720405\n","Device 0 - Train time: 4.887619963 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.49it/s]\n","Loss: 9.964656591415405%\n","Epoch: 175, Training loss: 7.598804103003608\n","Device 0 - Train time: 4.90535981 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 175, Training loss: 7.622735977172852\n","Device 1 - Train time: 7.67986747 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.32it/s]\n","Loss: 9.964595079421997%\n","Epoch: 176, Training loss: 7.623327043321398\n","Device 1 - Train time: 7.701131183 sec\n","Epoch: 176, Training loss: 7.599012851715088\n","Device 0 - Train time: 4.927099525 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.61it/s]\n","Loss: 9.964531660079956%\n","Epoch: 177, Training loss: 7.599115265740289\n","Device 0 - Train time: 4.891419209 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 177, Training loss: 7.622871081034343\n","Device 1 - Train time: 7.669213806 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.36it/s]\n","Loss: 9.964468955993652%\n","Epoch: 178, Training loss: 7.599012109968397\n","Device 0 - Train time: 4.91700944 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 178, Training loss: 7.622663338979085\n","Device 1 - Train time: 7.691686258 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.33it/s]\n","Loss: 9.964406728744507%\n","Epoch: 179, Training loss: 7.599088350931804\n","Device 0 - Train time: 4.897632769 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 179, Training loss: 7.622903823852539\n","Device 1 - Train time: 7.690317806 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.31it/s]\n","Loss: 9.964343070983887%\n","Epoch: 180, Training loss: 7.598668840196398\n","Device 0 - Train time: 4.840224267 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 180, Training loss: 7.622820218404134\n","Device 1 - Train time: 7.66457508 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.94it/s]\n","Loss: 9.964281558990479%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 181, Training loss: 7.622344228956434\n","Device 1 - Train time: 8.19614794 sec\n","Epoch: 181, Training loss: 7.599155161115858\n","Device 0 - Train time: 4.885606814 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.40it/s]\n","Loss: 9.964218854904175%\n","Epoch: 182, Training loss: 7.622296545240614\n","Device 1 - Train time: 7.64163051 sec\n","Epoch: 182, Training loss: 7.5986989339192705\n","Device 0 - Train time: 4.859490348 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.38it/s]\n","Loss: 9.964155197143555%\n","Epoch: 183, Training loss: 7.622631549835205\n","Device 1 - Train time: 7.667574425 sec\n","Epoch: 183, Training loss: 7.598640653822157\n","Device 0 - Train time: 4.892564879 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.59it/s]\n","Loss: 9.964092254638672%\n","Epoch: 184, Training loss: 7.598440117306179\n","Device 0 - Train time: 4.904032608 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 184, Training loss: 7.622000164455837\n","Device 1 - Train time: 7.673973379 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.36it/s]\n","Loss: 9.964030504226685%\n","Epoch: 185, Training loss: 7.622323671976726\n","Device 1 - Train time: 7.678867586 sec\n","Epoch: 185, Training loss: 7.598304271697998\n","Device 0 - Train time: 4.905376052 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.47it/s]\n","Loss: 9.963968276977539%\n","Epoch: 186, Training loss: 7.59900516933865\n","Device 0 - Train time: 4.849156677 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 186, Training loss: 7.622919453514947\n","Device 1 - Train time: 7.66927571 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.20it/s]\n","Loss: 9.963903665542603%\n","Epoch: 187, Training loss: 7.6225696669684515\n","Device 1 - Train time: 7.589010431 sec\n","Epoch: 187, Training loss: 7.598445574442546\n","Device 0 - Train time: 4.877408329 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.73it/s]\n","Loss: 9.963842153549194%\n","Epoch: 188, Training loss: 7.5981268882751465\n","Epoch: 188, Training loss: 7.622154341803657\n","Device 0 - Train time: 4.863189381 sec\n","Device 1 - Train time: 7.6526883 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.25it/s]\n","Loss: 9.96377944946289%\n","Epoch: 189, Training loss: 7.598579353756374\n","Device 0 - Train time: 4.856344338 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 189, Training loss: 7.622505770789252\n","Device 1 - Train time: 7.66770851 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.27it/s]\n","Loss: 9.96371603012085%\n","Epoch: 190, Training loss: 7.6220179133945045\n","Device 1 - Train time: 7.655212483 sec\n","Epoch: 190, Training loss: 7.598083019256592\n","Device 0 - Train time: 4.882476411 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 22.98it/s]\n","Loss: 9.963653802871704%\n","=> saved checkpoint for epoch -1 at checkpoints/model.pt\n","Epoch: 191, Training loss: 7.598202334509955\n","Device 0 - Train time: 4.86789762 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 191, Training loss: 7.62190130021837\n","Device 1 - Train time: 8.230226234 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.44it/s]\n","Loss: 9.9635910987854%\n","Epoch: 192, Training loss: 7.598318099975586\n","Device 0 - Train time: 4.885520979 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 192, Training loss: 7.622454060448541\n","Device 1 - Train time: 7.657261172 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.39it/s]\n","Loss: 9.963528156280518%\n","Epoch: 193, Training loss: 7.622141202290853\n","Device 1 - Train time: 7.650422919 sec\n","Epoch: 193, Training loss: 7.598276297251384\n","Device 0 - Train time: 4.878363407 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.58it/s]\n","Loss: 9.963465929031372%\n","Epoch: 194, Training loss: 7.62206686867608\n","Device 1 - Train time: 7.6573058 sec\n","Epoch: 194, Training loss: 7.598177433013916\n","Device 0 - Train time: 4.912499037 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.69it/s]\n","Loss: 9.963403224945068%\n","Epoch: 195, Training loss: 7.598082171546088\n","Device 0 - Train time: 4.910551494 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 195, Training loss: 7.622080590989855\n","Device 1 - Train time: 7.677296444 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.15it/s]\n","Loss: 9.963341236114502%\n","Epoch: 196, Training loss: 7.598662588331434\n","Device 0 - Train time: 4.871085985 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 196, Training loss: 7.62155654695299\n","Device 1 - Train time: 7.679617523 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.51it/s]\n","Loss: 9.963277816772461%\n","Epoch: 197, Training loss: 7.621950573391384\n","Device 1 - Train time: 7.682667909 sec\n","Epoch: 197, Training loss: 7.598188877105713\n","Device 0 - Train time: 4.922098302 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.19it/s]\n","Loss: 9.963214874267578%\n","Epoch: 198, Training loss: 7.598043441772461\n","Device 0 - Train time: 4.860550955 sec\n","  0%|                                                    | 0/65 [00:00<?, ?it/s]Epoch: 198, Training loss: 7.622028933631049\n","Device 1 - Train time: 7.677842738 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.38it/s]\n","Loss: 9.963152170181274%\n","Epoch: 199, Training loss: 7.622147454155816\n","Device 1 - Train time: 7.631983561 sec\n","Epoch: 199, Training loss: 7.598088529374865\n","Device 0 - Train time: 4.863909648 sec\n","100%|███████████████████████████████████████████| 65/65 [00:02<00:00, 23.71it/s]\n","Loss: 9.963090181350708%\n"]}],"source":["!python main.py"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting inference.py\n"]}],"source":["%%writefile inference.py\n","import torch\n","import torch.multiprocessing as mp\n","\n","from model import GPT\n","from utils import setup\n","from state import load_checkpoint, save_checkpoint\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","from tokenizers import Tokenizer\n","from objects import TokenizerWrapper\n","\n","import os\n","\n","def example(rank, world_size):\n","\n","    setup(rank, world_size)\n","    tokenizer = Tokenizer.from_file(\"data/tokenizer.json\")\n","    prefix = \"<bos> A thou\"\n","\n","\n","    model_config = dict(\n","        num_layers=12,\n","        num_heads=12,\n","        hidden_dim=768,\n","        ffc_hidden_dim=3072,\n","        max_seq_len=512,\n","        vocab_size=tokenizer.get_vocab_size()\n","    )\n","\n","    parallel_model = DDP(GPT(**model_config).to(rank))\n","    parallel_model.load_state_dict(torch.load(\"checkpoints/model.pt\", map_location={str(rank): 'cuda:0'})['model']\n","    )\n","    parallel_model.eval()\n","\n","    tokenizerwrapped = TokenizerWrapper(tokenizer, 0)\n","    batch = tokenizerwrapped(prefix, batch=False)\n","\n","    \n","    num_generations = 400\n","    with torch.cuda.amp.autocast():\n","        for i in range(num_generations):\n","            attn_mask = batch['attn_mask']\n","            curr_num_tokens = batch['input_ids'].shape[-1]\n","            outputs = parallel_model(batch['input_ids'].cuda(rank), attn_mask.cuda(rank))\n","            probs = outputs[0, -1].div(0.8).softmax(-1)\n","            token = torch.multinomial(probs, 1).view([])\n","\n","            print(tokenizerwrapped.tokenizer.decode([token]), end=' ', flush=True)\n","            batch = dict(input_ids=outputs[0, -1].argmax(-1).reshape(1, 1),\n","                         attn_mask=torch.ones(1, curr_num_tokens+1, requires_grad=False).cuda(rank))\n","\n","        \n","    \n","if __name__ == \"__main__\":\n","\n","    world_size = 1\n","    mp.spawn(example,\n","        args=(world_size,),\n","        nprocs=world_size,\n","        join=True)\n","\n","\n"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fie                                                                                                                                                                                                                                                                                                                                                                                                                "]}],"source":["!python inference.py\n","#inference is bad. I think its due to data..."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
