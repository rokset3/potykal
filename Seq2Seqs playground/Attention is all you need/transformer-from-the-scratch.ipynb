{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torch torchtext","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-10T23:31:21.059431Z","iopub.execute_input":"2023-07-10T23:31:21.060069Z","iopub.status.idle":"2023-07-10T23:31:35.870986Z","shell.execute_reply.started":"2023-07-10T23:31:21.060016Z","shell.execute_reply":"2023-07-10T23:31:35.869757Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: torchtext in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext) (4.64.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.28.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext) (1.23.5)\nRequirement already satisfied: torchdata in /opt/conda/lib/python3.10/site-packages (from torchtext) (0.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Resources used: \n* https://peterbloem.nl/blog/transformers","metadata":{}},{"cell_type":"markdown","source":"# Notes on this implementation:\n* I used simple approach, with smaller model (hidden_dim=100, seq_len=10, num_heads=4)\n* Here during inference I use greedy decoding. For further work, some top_p, top_k, beam_search can be implemented\n* Task is simple -> digit sorter","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchinfo import summary\nfrom torch.nn import functional as F\nimport numpy as np\n\nfrom typing import Optional, Union, List","metadata":{"execution":{"iopub.status.busy":"2023-07-11T02:01:05.748729Z","iopub.execute_input":"2023-07-11T02:01:05.749286Z","iopub.status.idle":"2023-07-11T02:01:09.829160Z","shell.execute_reply.started":"2023-07-11T02:01:05.749249Z","shell.execute_reply":"2023-07-11T02:01:09.828007Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"q = torch.randn((32, 10, 100))\nk = torch.randn((32, 10, 100))\nv = torch.randn((32, 10, 100))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.315051Z","iopub.execute_input":"2023-07-10T23:31:39.315635Z","iopub.status.idle":"2023-07-10T23:31:39.342621Z","shell.execute_reply.started":"2023-07-10T23:31:39.315601Z","shell.execute_reply":"2023-07-10T23:31:39.341767Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"scores = q @ k.transpose(2, 1)/q.shape[-1]\nscores = scores.masked_fill(my_mask.squeeze()==0, -1e9)\nprobs = ","metadata":{"execution":{"iopub.status.busy":"2023-06-27T15:02:48.042602Z","iopub.execute_input":"2023-06-27T15:02:48.043023Z","iopub.status.idle":"2023-06-27T15:02:48.057305Z","shell.execute_reply.started":"2023-06-27T15:02:48.042981Z","shell.execute_reply":"2023-06-27T15:02:48.055827Z"}}},{"cell_type":"markdown","source":"### Input, masks & Embeddings","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    \n    def __init__(self,\n                 hidden_size:int=100,\n                 seq_len: int=10,\n                 device: str='cpu'):\n        super().__init__()\n\n        self.encoding = torch.zeros(seq_len, hidden_size)\n        self.encoding.requires_grad = False  \n\n        pos = torch.arange(0, seq_len)\n        pos = pos.float().unsqueeze(dim=1)\n\n        _2i = torch.arange(0, hidden_size, step=2).float()\n        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / hidden_size)))\n        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / hidden_size)))\n        self.encoding = self.encoding.to(device)\n\n    def forward(self, x):\n        batch_size, seq_len = x.size()\n\n        return self.encoding[:seq_len, :].expand(batch_size, -1, -1)\n    \nclass EmbeddingLayer(nn.Module):\n    def __init__(self,\n                 hidden_size: int=100,\n                 seq_len: int=10,\n                 vocab_size: int=10,\n                 dropout: float=0.0,\n                 device: str='cpu'):\n        super().__init__()\n        self.pos_emb = PositionalEncoding(hidden_size, seq_len, device)\n        self.token_emb = nn.Embedding(vocab_size, hidden_size)\n        self.dropout = nn.Dropout(p=dropout)\n        \n    def forward(self, x):\n        return self.dropout(self.pos_emb(x) + self.token_emb(x))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:47:25.912643Z","iopub.execute_input":"2023-07-10T23:47:25.913023Z","iopub.status.idle":"2023-07-10T23:47:25.924605Z","shell.execute_reply.started":"2023-07-10T23:47:25.912989Z","shell.execute_reply":"2023-07-10T23:47:25.923543Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def subsequent_mask(size):\n    attn_shape = (1, size, size)\n    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n    return torch.from_numpy(subsequent_mask) == 0","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.368861Z","iopub.execute_input":"2023-07-10T23:31:39.371468Z","iopub.status.idle":"2023-07-10T23:31:39.378599Z","shell.execute_reply.started":"2023-07-10T23:31:39.371436Z","shell.execute_reply":"2023-07-10T23:31:39.377684Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Multihead Self Attention ","metadata":{}},{"cell_type":"code","source":"from typing import Callable, Optional\ndef attention_fn(q: torch.Tensor,\n                 k: torch.Tensor,\n                 v: torch.Tensor,\n                 mask: Optional[torch.Tensor]=None,\n                 dropout: Optional[torch.nn.Module]=None,\n                 return_attn_probs: bool=False):\n    \n    assert q.dim() == 3, \"expected to have 3 dims in shapes\"\n    assert q.shape == k.shape == v.shape, \"shapes are different\"\n    \n    dk = torch.tensor(q.shape[-1])\n    attn_output = None\n    \n    # Calculate scaled dot product with mask\n    scaled_dot_product = q @ k.transpose(2, 1) / torch.sqrt(dk) #assuming, that q, k, v have shape (bs, N, hidden_dim)\n    if mask is not None:\n        scaled_dot_product = scaled_dot_product.masked_fill(mask==0, -1e9)\n    \n    # Calculate softmax and apply dropout if passed as a module\n    attn_probs = F.softmax(scaled_dot_product, dim=-1)    \n    if dropout:\n        attn_probs = dropout(attn_probs)\n    \n    attn_output = attn_probs @ v \n    \n    if return_attn_probs == True:\n        return attn_output, attn_probs\n    else:\n        return attn_output, None\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.383091Z","iopub.execute_input":"2023-07-10T23:31:39.385739Z","iopub.status.idle":"2023-07-10T23:31:39.397752Z","shell.execute_reply.started":"2023-07-10T23:31:39.385705Z","shell.execute_reply":"2023-07-10T23:31:39.396851Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MultiheadSelfAttention(nn.Module):\n    def __init__(self,\n                 hidden_dim: int=100,\n                 num_heads: int=4, \n                 dropout: Optional[float]=None, #attn dropout\n                 ):\n        super().__init__()\n        assert hidden_dim % num_heads == 0  \n        self.hidden_dim = hidden_dim \n        self.num_heads = num_heads\n        \n        self.tokeys = nn.Linear(self.hidden_dim, self.hidden_dim)\n        self.tovalues = nn.Linear(self.hidden_dim, self.hidden_dim)\n        self.toqueries = nn.Linear(self.hidden_dim, self.hidden_dim)\n        \n        self.wo = nn.Linear(self.hidden_dim, self.hidden_dim)\n        \n        self.attn_output = None\n        self.dropout = None\n        if dropout is not None:\n            self.dropout = nn.Dropout(p=dropout)\n        \n    def forward(self,\n                q: torch.Tensor,\n                k: torch.Tensor,\n                v: torch.Tensor,\n                mask: Optional[torch.Tensor]=None,\n                return_attn_probs: bool=False\n                ):\n        \n        assert q.size() == k.size() == v.size()\n        if mask is not None:\n            assert mask.shape[-1] == q.shape[-2]                    #size mask == input_shape of q/k/v\n        \n        b_size, n, hidden_dim = q.size()\n        \n        assert hidden_dim % self.num_heads == 0\n        head_hidden_dim = hidden_dim // self.num_heads\n        num_heads = self.num_heads\n        \n        queries = self.toqueries(q)\n        keys = self.tokeys(k)\n        values = self.tovalues(v)\n        \n        # to have shape = (b_size, num_heads, head_hidden_dim, n), to then fold heads into batchsizes \n        queries = queries.view(b_size, n, num_heads, head_hidden_dim).transpose(1, 2).contiguous() \n        keys    = keys   .view(b_size, n, num_heads, head_hidden_dim).transpose(1, 2).contiguous() \n        values  = values .view(b_size, n, num_heads, head_hidden_dim).transpose(1, 2).contiguous()\n        \n        queries = queries.view(b_size * num_heads, n, head_hidden_dim)\n        keys    = keys   .view(b_size * num_heads, n, head_hidden_dim)\n        values  = values .view(b_size * num_heads, n, head_hidden_dim)\n        \n        attn_output, attn_probs = attention_fn(q=queries,\n                                   k=keys,\n                                   v=values,\n                                   mask=mask,\n                                   dropout=self.dropout,\n                                   return_attn_probs=return_attn_probs)\n        \n        attn_output = attn_output.view(b_size, num_heads, n, head_hidden_dim)\n        attn_output = attn_output.transpose(1, 2).contiguous().view(b_size, n, head_hidden_dim * num_heads)\n        attn_output = self.wo(attn_output)\n        if return_attn_probs:\n            attn_probs = attn_probs.view(b_size, num_heads, n, n)\n            attn_probs = attn_probs.transpose(1, 2).contiguous().view(b_size, n, n * num_heads)\n        \n        return attn_output, attn_probs\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:47:30.053532Z","iopub.execute_input":"2023-07-10T23:47:30.053932Z","iopub.status.idle":"2023-07-10T23:47:30.070464Z","shell.execute_reply.started":"2023-07-10T23:47:30.053901Z","shell.execute_reply":"2023-07-10T23:47:30.069428Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self,\n                 hidden_dim: int=100,\n                 num_heads: int=4,\n                 attn_dropout: float=0.0,\n                 mlp_dropout: float=0.0,\n                 mlp_scale: int=4,):\n    \n        super().__init__()\n        self.mha = MultiheadSelfAttention(hidden_dim=hidden_dim,\n                                          num_heads=num_heads,\n                                          dropout=attn_dropout,)\n        self.mlp = nn.Sequential(nn.Linear(in_features=hidden_dim,\n                                           out_features=mlp_scale * hidden_dim,),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=mlp_dropout),\n                                 nn.Linear(in_features=hidden_dim * mlp_scale,\n                                           out_features=hidden_dim))\n        \n        self.layernorm_layers = nn.ModuleList([nn.LayerNorm(normalized_shape=hidden_dim),\n                                 nn.LayerNorm(normalized_shape=hidden_dim)])\n        \n    def forward(self,\n                x: torch.Tensor,\n                src_mask: Optional[torch.Tensor]=None)->torch.Tensor:\n        x = self.layernorm_layers[0](self.mha(x, x, x, mask=src_mask)[0] + x)\n        x = self.layernorm_layers[1](self.mlp(x) + x)\n        return x\n        \n        \nclass EncoderBlock(nn.Module):\n    def __init__(self,\n                 num_layers: int=4,\n                 hidden_dim: int=100,\n                 num_heads: int=4,\n                 attn_dropout: float=0.0,\n                 mlp_dropout: float=0.0,\n                 mlp_scale: int=4,):\n        super().__init__()\n        self.layers = nn.ModuleList([EncoderLayer(hidden_dim,\n                                                  num_heads,\n                                                  attn_dropout,\n                                                  mlp_dropout,\n                                                  mlp_scale) for _ in range(num_layers)])\n    def forward(self, \n                x: torch.Tensor,\n                src_mask: Optional[torch.Tensor]=None) -> torch.Tensor:\n        for layer in self.layers:\n            x = layer(x, src_mask)\n            \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:47:30.781695Z","iopub.execute_input":"2023-07-10T23:47:30.782026Z","iopub.status.idle":"2023-07-10T23:47:30.794423Z","shell.execute_reply.started":"2023-07-10T23:47:30.782000Z","shell.execute_reply":"2023-07-10T23:47:30.793525Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"encoder = EncoderBlock()\ntest_sample = torch.randn(32, 10, 100)\n\nsummary(encoder,\n        input_data=test_sample,\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.456755Z","iopub.execute_input":"2023-07-10T23:31:39.459343Z","iopub.status.idle":"2023-07-10T23:31:39.636451Z","shell.execute_reply.started":"2023-07-10T23:31:39.459308Z","shell.execute_reply":"2023-07-10T23:31:39.635575Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"=============================================================================================================================\nLayer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n=============================================================================================================================\nEncoderBlock (EncoderBlock)                   [32, 10, 100]        [32, 10, 100]        --                   True\n├─ModuleList (layers)                         --                   --                   --                   True\n│    └─EncoderLayer (0)                       [32, 10, 100]        [32, 10, 100]        --                   True\n│    │    └─MultiheadSelfAttention (mha)      [32, 10, 100]        [32, 10, 100]        40,400               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n│    │    └─Sequential (mlp)                  [32, 10, 100]        [32, 10, 100]        80,500               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n│    └─EncoderLayer (1)                       [32, 10, 100]        [32, 10, 100]        --                   True\n│    │    └─MultiheadSelfAttention (mha)      [32, 10, 100]        [32, 10, 100]        40,400               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n│    │    └─Sequential (mlp)                  [32, 10, 100]        [32, 10, 100]        80,500               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n│    └─EncoderLayer (2)                       [32, 10, 100]        [32, 10, 100]        --                   True\n│    │    └─MultiheadSelfAttention (mha)      [32, 10, 100]        [32, 10, 100]        40,400               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n│    │    └─Sequential (mlp)                  [32, 10, 100]        [32, 10, 100]        80,500               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n│    └─EncoderLayer (3)                       [32, 10, 100]        [32, 10, 100]        --                   True\n│    │    └─MultiheadSelfAttention (mha)      [32, 10, 100]        [32, 10, 100]        40,400               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n│    │    └─Sequential (mlp)                  [32, 10, 100]        [32, 10, 100]        80,500               True\n│    │    └─ModuleList (layernorm_layers)     --                   --                   (recursive)          True\n=============================================================================================================================\nTotal params: 485,200\nTrainable params: 485,200\nNon-trainable params: 0\nTotal mult-adds (M): 15.53\n=============================================================================================================================\nInput size (MB): 0.13\nForward/backward pass size (MB): 11.26\nParams size (MB): 1.94\nEstimated Total Size (MB): 13.33\n============================================================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, \n                 hidden_dim: int=100,\n                 num_heads: int=4,\n                 attn_dropout: float=0.0,\n                 mlp_dropout: float=0.0,\n                 mlp_scale: int=4):\n        super().__init__()\n        self.masked_mha = MultiheadSelfAttention(hidden_dim=hidden_dim,\n                                                 num_heads=num_heads,\n                                                 dropout=attn_dropout)\n        self.enc_dec_mha = MultiheadSelfAttention(hidden_dim=hidden_dim,\n                                                 num_heads=num_heads,\n                                                 dropout=attn_dropout)\n        self.mlp = nn.Sequential(nn.Linear(hidden_dim, hidden_dim * mlp_scale),\n                                 nn.ReLU(),\n                                 nn.Dropout(mlp_dropout),\n                                 nn.Linear(hidden_dim * mlp_scale, hidden_dim))\n        self.layernorm_layers = nn.ModuleList([nn.LayerNorm(normalized_shape=hidden_dim) for _ in range(3)])\n        \n    def forward(self,\n                x_dec: torch.Tensor,\n                x_enc: torch.Tensor,\n                trg_mask: Optional[torch.Tensor],\n                src_mask: Optional[torch.Tensor]=None)->torch.Tensor:\n        x = self.layernorm_layers[0](self.masked_mha(x_dec, x_dec, x_dec, mask=trg_mask)[0] + x_dec)\n        x = self.layernorm_layers[1](self.enc_dec_mha(x_enc, x_enc, x_dec, mask=src_mask)[0] + x_dec)\n        x = self.layernorm_layers[2](self.mlp(x) + x)\n        \n        return x\n    \n    \nclass DecoderBlock(nn.Module):\n    def __init__(self,\n                 num_layers: int=4,\n                 hidden_dim: int=100,\n                 num_heads: int=4,\n                 attn_dropout: float=0.0,\n                 mlp_dropout: float=0.0,\n                 mlp_scale: int=4):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            DecoderLayer(hidden_dim=hidden_dim,\n                         num_heads=num_heads,\n                         attn_dropout=attn_dropout,\n                         mlp_dropout=mlp_dropout,\n                         mlp_scale=mlp_scale)\n            for _ in range(num_layers)\n        ])\n        \n    def forward(self,\n                x_dec: torch.Tensor,\n                x_enc: torch.Tensor,\n                trg_mask: Optional[torch.Tensor]=None,\n                src_mask: Optional[torch.Tensor]=None,)-> torch.Tensor:\n        for layer in self.layers:\n            x = layer(x_dec, x_enc, trg_mask, src_mask)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:47:32.772253Z","iopub.execute_input":"2023-07-10T23:47:32.773169Z","iopub.status.idle":"2023-07-10T23:47:32.787327Z","shell.execute_reply.started":"2023-07-10T23:47:32.773123Z","shell.execute_reply":"2023-07-10T23:47:32.786146Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"### Transformer itself","metadata":{}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self,\n                 num_layers: int=4,\n                 hidden_dim: int=100,\n                 num_heads: int=4,\n                 attn_dropout: float=0.0,\n                 mlp_dropout: float=0.0,\n                 mlp_scale: int=4,\n                 seq_len: int=10,\n                 vocab_size: int=10,\n                 emb_dropout: float=0.0,\n                 device: str='cpu'\n                ):\n        super().__init__()\n        self.emb = EmbeddingLayer(hidden_dim, seq_len, vocab_size, emb_dropout, device)\n        self.encoder = EncoderBlock(num_layers, hidden_dim, num_heads, attn_dropout, mlp_dropout, mlp_scale)\n        self.decoder = DecoderBlock(num_layers, hidden_dim, num_heads, attn_dropout, mlp_dropout, mlp_scale)\n        self.linear = nn.Linear(hidden_dim, vocab_size)\n        \n    def forward(self,\n                src: torch.Tensor,\n                tgt: torch.Tensor,\n                src_mask: torch.Tensor,\n                tgt_mask: torch.Tensor) -> torch.Tensor:\n        src = self.emb(src)\n        tgt = self.emb(tgt)\n\n        encoder_output = self.encoder(src, src_mask)\n        decoder_output = self.decoder(tgt, encoder_output, tgt_mask, src_mask)\n        \n        return self.linear(decoder_output)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:49:35.079930Z","iopub.execute_input":"2023-07-10T23:49:35.080306Z","iopub.status.idle":"2023-07-10T23:49:35.092829Z","shell.execute_reply.started":"2023-07-10T23:49:35.080275Z","shell.execute_reply":"2023-07-10T23:49:35.091899Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"### Test sample","metadata":{}},{"cell_type":"code","source":"tgt_mask = subsequent_mask(10)\nsrc_mask = torch.ones(1, 10, 10)\nsource = torch.arange(0, 10).unsqueeze(0)\ntarget = torch.arange(9, -1, step=-1).unsqueeze(0)\n\ntest_sample = (source, target, src_mask, tgt_mask)\ntransformer = Transformer()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.689392Z","iopub.execute_input":"2023-07-10T23:31:39.691993Z","iopub.status.idle":"2023-07-10T23:31:39.755632Z","shell.execute_reply.started":"2023-07-10T23:31:39.691960Z","shell.execute_reply":"2023-07-10T23:31:39.754714Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"summary(transformer,\n        input_data=test_sample,\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.759912Z","iopub.execute_input":"2023-07-10T23:31:39.762276Z","iopub.status.idle":"2023-07-10T23:31:39.848693Z","shell.execute_reply.started":"2023-07-10T23:31:39.762240Z","shell.execute_reply":"2023-07-10T23:31:39.847851Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"============================================================================================================================================\nLayer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n============================================================================================================================================\nTransformer (Transformer)                                    [1, 10]              [1, 10, 4]           --                   True\n├─EmbeddingLayer (emb)                                       [1, 10]              [1, 10, 100]         --                   True\n│    └─PositionalEncoding (pos_emb)                          [1, 10]              [1, 10, 100]         --                   --\n│    └─Embedding (token_emb)                                 [1, 10]              [1, 10, 100]         1,000                True\n│    └─Dropout (dropout)                                     [1, 10, 100]         [1, 10, 100]         --                   --\n├─EmbeddingLayer (emb)                                       [1, 10]              [1, 10, 100]         (recursive)          True\n│    └─PositionalEncoding (pos_emb)                          [1, 10]              [1, 10, 100]         --                   --\n│    └─Embedding (token_emb)                                 [1, 10]              [1, 10, 100]         (recursive)          True\n│    └─Dropout (dropout)                                     [1, 10, 100]         [1, 10, 100]         --                   --\n├─EncoderBlock (encoder)                                     [1, 10, 100]         [1, 10, 100]         --                   True\n│    └─ModuleList (layers)                                   --                   --                   --                   True\n│    │    └─EncoderLayer (0)                                 [1, 10, 100]         [1, 10, 100]         121,300              True\n│    │    └─EncoderLayer (1)                                 [1, 10, 100]         [1, 10, 100]         121,300              True\n│    │    └─EncoderLayer (2)                                 [1, 10, 100]         [1, 10, 100]         121,300              True\n│    │    └─EncoderLayer (3)                                 [1, 10, 100]         [1, 10, 100]         121,300              True\n├─DecoderBlock (decoder)                                     [1, 10, 100]         [1, 10, 100]         --                   True\n│    └─ModuleList (layers)                                   --                   --                   --                   True\n│    │    └─DecoderLayer (0)                                 [1, 10, 100]         [1, 10, 100]         161,900              True\n│    │    └─DecoderLayer (1)                                 [1, 10, 100]         [1, 10, 100]         161,900              True\n│    │    └─DecoderLayer (2)                                 [1, 10, 100]         [1, 10, 100]         161,900              True\n│    │    └─DecoderLayer (3)                                 [1, 10, 100]         [1, 10, 100]         161,900              True\n├─Linear (linear)                                            [1, 10, 100]         [1, 10, 4]           404                  True\n============================================================================================================================================\nTotal params: 1,134,204\nTrainable params: 1,134,204\nNon-trainable params: 0\nTotal mult-adds (M): 1.14\n============================================================================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.88\nParams size (MB): 4.54\nEstimated Total Size (MB): 5.42\n============================================================================================================================================"},"metadata":{}}]},{"cell_type":"code","source":"transformer(source, target, src_mask, tgt_mask).shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.852720Z","iopub.execute_input":"2023-07-10T23:31:39.854936Z","iopub.status.idle":"2023-07-10T23:31:39.885863Z","shell.execute_reply.started":"2023-07-10T23:31:39.854902Z","shell.execute_reply":"2023-07-10T23:31:39.885018Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 10, 4])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Digit inverter\n* Given list of digits from range(0-9), we want to sort them in descending order","metadata":{}},{"cell_type":"markdown","source":"### Data Generation and workings","metadata":{}},{"cell_type":"code","source":"### I dont need tokenizer here\nX_train = torch.randint(high=9,size=(5000, 10))\ny_train = torch.sort(X_train, dim=-1, descending=True).values\n\nX_test = torch.randint(high=9, size=(1000, 10))\ny_test = torch.sort(X_test, dim=-1, descending=True).values","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.889942Z","iopub.execute_input":"2023-07-10T23:31:39.892216Z","iopub.status.idle":"2023-07-10T23:31:39.909677Z","shell.execute_reply.started":"2023-07-10T23:31:39.892182Z","shell.execute_reply":"2023-07-10T23:31:39.908855Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nclass MyDataset(Dataset):\n    def __init__(self, \n                 source: torch.Tensor,\n                 target: torch.Tensor):\n        self.source = source\n        self.target = target\n        \n    def __len__(self,):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source = self.source[idx]\n        target = self.target[idx]\n        return source, target\n    \n# some simple \"tokenizer\" to have items as an input, and returns masks with tokens_id\n# (in this case i dont need tokens_id's since im using integers as input)    \ndef tiktokenizer(batch: torch.utils.data.DataLoader,\n                 seq_len: int=10,\n                 device: str='cpu') -> torch.Tensor:\n    source = batch[0].to(device)\n    target = batch[1].to(device)\n    \n    batch_size = len(source)\n    \n    source_mask = torch.ones(1, seq_len, seq_len).to(device)\n    tgt_mask = subsequent_mask(seq_len).to(device)\n    \n    outputs = {'source': source,\n               'target': target,\n               'src_mask': source_mask,\n               'tgt_mask': tgt_mask}\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:31:39.927065Z","iopub.execute_input":"2023-07-10T23:31:39.929625Z","iopub.status.idle":"2023-07-10T23:31:39.937742Z","shell.execute_reply.started":"2023-07-10T23:31:39.929591Z","shell.execute_reply":"2023-07-10T23:31:39.936931Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(source=X_train, target=y_train)\ntest_dataset = Dataset(source=X_test, target=y_test)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, )\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T23:47:41.182054Z","iopub.execute_input":"2023-07-10T23:47:41.182438Z","iopub.status.idle":"2023-07-10T23:47:41.187941Z","shell.execute_reply.started":"2023-07-10T23:47:41.182410Z","shell.execute_reply":"2023-07-10T23:47:41.186863Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"### Training loop and stuff","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = Transformer(device=device).to(device) #with basic params\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T00:13:51.359656Z","iopub.execute_input":"2023-07-11T00:13:51.360605Z","iopub.status.idle":"2023-07-11T00:13:51.396955Z","shell.execute_reply.started":"2023-07-11T00:13:51.360561Z","shell.execute_reply":"2023-07-11T00:13:51.396017Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch,\n                    model, \n                    train_dataloader,\n                    loss_fn,\n                    optimizer,\n                    device):\n    model.train()\n    train_loss = 0\n    for batch_num, batch in enumerate(train_dataloader):\n        inputs = tiktokenizer(batch,\n                              seq_len=10,\n                              device=device)\n\n        outputs = model(src=inputs['source'],\n                        tgt=inputs['target'],\n                        src_mask=inputs['src_mask'],\n                        tgt_mask=inputs['tgt_mask'])\n        \n        optimizer.zero_grad()\n        loss = loss_fn(outputs, inputs['target'])\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n    train_loss /= batch_num \n    \n    print(f'Epoch: {epoch} Train loss: {train_loss}')\n    return train_loss\n    \n    \ndef valid_one_epoch(epoch,\n                    model: torch.nn.Module,\n                    test_dataloader: torch.utils.data.DataLoader,\n                    loss_fn: torch.nn.Module,\n                    device):\n    model.eval()\n    with torch.no_grad():\n        eval_loss = 0\n        for batch_num, batch in enumerate(test_dataloader):\n            inputs = tiktokenizer(batch,\n                                  seq_len=10,\n                                  device=device)\n\n            outputs = model(src=inputs['source'],\n                            tgt=inputs['target'],\n                            src_mask=inputs['src_mask'],\n                            tgt_mask=inputs['tgt_mask'])\n\n            loss = loss_fn(outputs, inputs['target'])\n            \n            eval_loss += loss.item()\n        \n        eval_loss /= batch_num\n        print(f'Epoch: {epoch} Test loss: {eval_loss}')\n        return eval_loss    ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T00:13:51.524180Z","iopub.execute_input":"2023-07-11T00:13:51.524513Z","iopub.status.idle":"2023-07-11T00:13:51.535727Z","shell.execute_reply.started":"2023-07-11T00:13:51.524485Z","shell.execute_reply":"2023-07-11T00:13:51.534638Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nhistory = {'train_loss':[],\n           'val_loss': []}\nnum_epochs = 50\n\nfor epoch in tqdm(range(num_epochs)):\n    history['train_loss'].append(train_one_epoch(epoch, model, train_dataloader, loss, optimizer, device))\n    history['val_loss'].append(valid_one_epoch(epoch, model, test_dataloader, loss, device))","metadata":{"execution":{"iopub.status.busy":"2023-07-11T00:13:51.673905Z","iopub.execute_input":"2023-07-11T00:13:51.674825Z","iopub.status.idle":"2023-07-11T00:16:50.797320Z","shell.execute_reply.started":"2023-07-11T00:13:51.674775Z","shell.execute_reply":"2023-07-11T00:16:50.796304Z"},"trusted":true},"execution_count":143,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db6a5a281f1404f979daea93a5bbbe6"}},"metadata":{}},{"name":"stdout","text":"Epoch: 0 Train loss: 0.8372713461136206\nEpoch: 0 Test loss: 0.594544582789944\nEpoch: 1 Train loss: 0.37167139895833456\nEpoch: 1 Test loss: 0.23044885839185408\nEpoch: 2 Train loss: 0.14090958650773153\nEpoch: 2 Test loss: 0.13332620431338588\nEpoch: 3 Train loss: 0.08700349246366666\nEpoch: 3 Test loss: 0.19044269957850057\nEpoch: 4 Train loss: 0.07409162669538115\nEpoch: 4 Test loss: 0.032013756343193596\nEpoch: 5 Train loss: 0.050700599050077684\nEpoch: 5 Test loss: 0.05569267837751296\nEpoch: 6 Train loss: 0.03469393156074847\nEpoch: 6 Test loss: 0.052735235061376326\nEpoch: 7 Train loss: 0.04246111947129695\nEpoch: 7 Test loss: 0.08533437069385283\nEpoch: 8 Train loss: 0.04411906387674837\nEpoch: 8 Test loss: 0.04830003860256364\nEpoch: 9 Train loss: 0.013592714396788953\nEpoch: 9 Test loss: 0.03129395333329035\nEpoch: 10 Train loss: 0.05707979446500152\nEpoch: 10 Test loss: 0.016446957567466364\nEpoch: 11 Train loss: 0.02464760314577665\nEpoch: 11 Test loss: 0.007450633669166916\nEpoch: 12 Train loss: 0.01632745993414667\nEpoch: 12 Test loss: 0.025476465722726237\nEpoch: 13 Train loss: 0.030198179128675316\nEpoch: 13 Test loss: 0.027322281212095293\nEpoch: 14 Train loss: 0.008296712673025187\nEpoch: 14 Test loss: 0.00686824903447902\nEpoch: 15 Train loss: 0.03149994735707505\nEpoch: 15 Test loss: 0.014366787167326096\nEpoch: 16 Train loss: 0.008739866630117504\nEpoch: 16 Test loss: 0.004682443279307336\nEpoch: 17 Train loss: 0.04380914000033114\nEpoch: 17 Test loss: 0.010872320140591793\nEpoch: 18 Train loss: 0.0031854230647485773\nEpoch: 18 Test loss: 0.0023611349479911187\nEpoch: 19 Train loss: 0.00208716549684304\nEpoch: 19 Test loss: 0.031235873901976213\nEpoch: 20 Train loss: 0.051823616186037466\nEpoch: 20 Test loss: 0.027902686592912482\nEpoch: 21 Train loss: 0.004950216989061282\nEpoch: 21 Test loss: 0.003042630870749558\nEpoch: 22 Train loss: 0.0022218501406967286\nEpoch: 22 Test loss: 0.0015406856926405922\nEpoch: 23 Train loss: 0.0008678181219669895\nEpoch: 23 Test loss: 0.0031040865627977427\nEpoch: 24 Train loss: 0.048450956381062636\nEpoch: 24 Test loss: 0.02660950345377768\nEpoch: 25 Train loss: 0.05347196352130805\nEpoch: 25 Test loss: 0.06450750564615573\nEpoch: 26 Train loss: 0.012091412481356364\nEpoch: 26 Test loss: 0.0033045594933472813\nEpoch: 27 Train loss: 0.0028136671405660217\nEpoch: 27 Test loss: 0.003524575638303143\nEpoch: 28 Train loss: 0.014326457891095346\nEpoch: 28 Test loss: 0.006339928136214674\nEpoch: 29 Train loss: 0.010582979374120418\nEpoch: 29 Test loss: 0.0040378788994970705\nEpoch: 30 Train loss: 0.006517164607337178\nEpoch: 30 Test loss: 0.06553843662503266\nEpoch: 31 Train loss: 0.03355921356108947\nEpoch: 31 Test loss: 0.007505206717929292\nEpoch: 32 Train loss: 0.013204145342266807\nEpoch: 32 Test loss: 0.0242690313006601\nEpoch: 33 Train loss: 0.019902147486274585\nEpoch: 33 Test loss: 0.03209676960062596\nEpoch: 34 Train loss: 0.01956239355114611\nEpoch: 34 Test loss: 0.010372158665690691\nEpoch: 35 Train loss: 0.01575761168407133\nEpoch: 35 Test loss: 0.022601532250372394\nEpoch: 36 Train loss: 0.012164102814634904\nEpoch: 36 Test loss: 0.05328682870153458\nEpoch: 37 Train loss: 0.03334902350159096\nEpoch: 37 Test loss: 0.04151593136691278\nEpoch: 38 Train loss: 0.0032875318439227366\nEpoch: 38 Test loss: 0.001589041862556065\nEpoch: 39 Train loss: 0.0005886675215454792\nEpoch: 39 Test loss: 0.001537555528439923\nEpoch: 40 Train loss: 0.0004448179465026232\nEpoch: 40 Test loss: 0.000977353369762568\nEpoch: 41 Train loss: 0.029474251497667397\nEpoch: 41 Test loss: 0.04819650428309556\nEpoch: 42 Train loss: 0.0196575444640938\nEpoch: 42 Test loss: 0.007555256990130029\nEpoch: 43 Train loss: 0.011104800715820136\nEpoch: 43 Test loss: 0.010180866660741758\nEpoch: 44 Train loss: 0.004686625844139296\nEpoch: 44 Test loss: 0.00628618951961999\nEpoch: 45 Train loss: 0.016035759283859547\nEpoch: 45 Test loss: 0.0074422177858650684\nEpoch: 46 Train loss: 0.022147005421664707\nEpoch: 46 Test loss: 0.10341132294026113\nEpoch: 47 Train loss: 0.043703410175415534\nEpoch: 47 Test loss: 0.0020269191501879943\nEpoch: 48 Train loss: 0.001965813214505593\nEpoch: 48 Test loss: 0.0019118096214726628\nEpoch: 49 Train loss: 0.00087402056646496\nEpoch: 49 Test loss: 0.0010140302823152347\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nplt.plot(range(num_epochs), history['train_loss'], label='Train')\nplt.plot(range(num_epochs), history['val_loss'], label='Val')\n\nplt.title('Loss curves')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T00:16:50.799269Z","iopub.execute_input":"2023-07-11T00:16:50.800519Z","iopub.status.idle":"2023-07-11T00:16:51.044242Z","shell.execute_reply.started":"2023-07-11T00:16:50.800483Z","shell.execute_reply":"2023-07-11T00:16:51.043332Z"},"trusted":true},"execution_count":144,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Inference check\nmodel.eval()\nbatch = next(iter(test_dataloader))\nwith torch.no_grad():\n    inputs = tiktokenizer(batch,\n                          seq_len=10,\n                          device=device)\n\n    outputs = model(src=inputs['source'],\n                    tgt=inputs['target'],\n                    src_mask=inputs['src_mask'],\n                    tgt_mask=inputs['tgt_mask'])\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T00:19:35.307440Z","iopub.execute_input":"2023-07-11T00:19:35.307838Z","iopub.status.idle":"2023-07-11T00:19:35.328686Z","shell.execute_reply.started":"2023-07-11T00:19:35.307779Z","shell.execute_reply":"2023-07-11T00:19:35.327780Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# Real source-target\nbatch[0][0], batch[1][0]","metadata":{"execution":{"iopub.status.busy":"2023-07-11T00:20:40.106853Z","iopub.execute_input":"2023-07-11T00:20:40.107261Z","iopub.status.idle":"2023-07-11T00:20:40.116245Z","shell.execute_reply.started":"2023-07-11T00:20:40.107231Z","shell.execute_reply":"2023-07-11T00:20:40.115186Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"(tensor([2, 4, 2, 2, 8, 2, 6, 7, 7, 0]),\n tensor([8, 7, 7, 6, 4, 2, 2, 2, 2, 0]))"},"metadata":{}}]},{"cell_type":"code","source":"# Model output\ntorch.argmax(outputs, dim=1)[0]","metadata":{"execution":{"iopub.status.busy":"2023-07-11T00:21:50.607782Z","iopub.execute_input":"2023-07-11T00:21:50.608355Z","iopub.status.idle":"2023-07-11T00:21:50.617262Z","shell.execute_reply.started":"2023-07-11T00:21:50.608314Z","shell.execute_reply":"2023-07-11T00:21:50.616292Z"},"trusted":true},"execution_count":167,"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"tensor([8, 7, 7, 6, 4, 2, 2, 2, 2, 0], device='cuda:0')"},"metadata":{}}]}]}