{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51c313b4b2b14583ac5b3a14d0e87ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47c3dafc8a7448629136872883719bd2",
              "IPY_MODEL_360d5e90ea8c4e2ea0f01bf031aa7268",
              "IPY_MODEL_0ea3bd9a4c704a0fb1ef490d4f9714ea"
            ],
            "layout": "IPY_MODEL_1f190959e9434a118254c27ab5d99fd9"
          }
        },
        "47c3dafc8a7448629136872883719bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d46d1423744995bd130fefc6c13af5",
            "placeholder": "​",
            "style": "IPY_MODEL_281fca9be67247218a7073e4a059387f",
            "value": "100%"
          }
        },
        "360d5e90ea8c4e2ea0f01bf031aa7268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74791f810ec14069aedd741798433956",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcd9691abd2f4ee2a65d5c8d371ec75a",
            "value": 100
          }
        },
        "0ea3bd9a4c704a0fb1ef490d4f9714ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f8b9f04cf04fd681973399ed2d68b5",
            "placeholder": "​",
            "style": "IPY_MODEL_b8387396ed2d4350b9a1fd594b56ff27",
            "value": " 100/100 [02:52&lt;00:00,  1.85s/it]"
          }
        },
        "1f190959e9434a118254c27ab5d99fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d46d1423744995bd130fefc6c13af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281fca9be67247218a7073e4a059387f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74791f810ec14069aedd741798433956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd9691abd2f4ee2a65d5c8d371ec75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8f8b9f04cf04fd681973399ed2d68b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8387396ed2d4350b9a1fd594b56ff27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLO99rWwabj5",
        "outputId": "2a2bf1d7-0d27-475b-b1e0-edf98a4b29d0"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "rMULnoPK0ZI4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from einops import rearrange, reduce, asnumpy, parse_shape\n",
        "from einops.layers.torch import Rearrange, Reduce"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4kaRfr_YZRGM",
        "outputId": "32f9e779-e190-44d9-9bf6-3be426a7cca7"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 source,\n",
        "                 target):\n",
        "        self.source = source\n",
        "        self.target = target\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self.source)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        output = dict(\n",
        "            src = self.source[idx],\n",
        "            tgt = self.target[idx]\n",
        "        )\n",
        "        return output"
      ],
      "metadata": {
        "id": "floj-equ0ZrH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10000\n",
        "seq_len = 5\n",
        "vocab_size = len(range(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "P4cbUOk-NbjL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randint(10, (num_samples, seq_len), requires_grad=False)\n",
        "y = torch.flip(X, dims=[1])\n",
        "y.requires_grad = False\n",
        "\n",
        "\n",
        "train_size = 0.9\n",
        "train_slice = int(train_size * num_samples)\n",
        "\n",
        "train_dataset = DigitDataset(X[:train_slice], y[: train_slice])\n",
        "test_dataset = DigitDataset(X[train_slice:], y[train_slice:])"
      ],
      "metadata": {
        "id": "QOuC8MGWN0VW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj4yi3hGO3ef",
        "outputId": "ece5f653-8573-4dfd-d379-5fd50a695bd9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.source[0], train_dataset.target[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32tifnwvPat2",
        "outputId": "1b283fff-5e10-48ca-f8a2-4cf3c1edf82b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([8, 2, 1, 1, 9]), tensor([9, 1, 1, 2, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.source[0], test_dataset.target[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuHi4dWgPsAT",
        "outputId": "bd50b5cf-4996-41f6-ff4a-f38089f6b325"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([9, 1, 1, 3, 0]), tensor([0, 3, 1, 1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True, drop_last=False, batch_size=512)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=False, drop_last=False, batch_size=512)"
      ],
      "metadata": {
        "id": "q_ttf4MTPw5z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input['src'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2upxcWXevYF",
        "outputId": "a3a22ac2-d828-4485-c9f2-c78ad321892f"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "haha = LSTMEncoder(nn.Embedding(10, 100),\n",
        "                   100, 4, 0.5, 0.5)\n",
        "hc = haha(test_input['src'])"
      ],
      "metadata": {
        "id": "ZvxCZJBHeHE5"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec = LSTMDecoder(nn.Embedding(10, 100),\n",
        "                  100,\n",
        "                  4,\n",
        "                  10,)\n"
      ],
      "metadata": {
        "id": "GjtRP9xuegjU"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec(test_input['tgt'][:, 0], hc)[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFR0c9BUghb8",
        "outputId": "1dff4534-5f39-4b66-a1fb-89a5d00e0651"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model itself"
      ],
      "metadata": {
        "id": "ltq1Ov9UP7_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils.path import target_outdated\n",
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedding_layer,\n",
        "                 hidden_size,\n",
        "                 num_layers,\n",
        "                 lstm_dropout,\n",
        "                 embedding_dropout):\n",
        "\n",
        "        super().__init__()\n",
        "        self.embedding_layer = embedding_layer\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_dropout = lstm_dropout\n",
        "        self.embedding_dropout = embedding_dropout\n",
        "        self.emb_dropout = nn.Dropout(p=self.embedding_dropout)\n",
        "\n",
        "        self.lstm_encoder = nn.LSTM(input_size=self.hidden_size,\n",
        "                                    hidden_size=self.hidden_size,\n",
        "                                    num_layers=self.num_layers,\n",
        "                                    dropout=self.lstm_dropout,\n",
        "                                    batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        batch_size = src.shape[1]\n",
        "        seq_len = src.shape[0]\n",
        "        _, hc = self.lstm_encoder(self.emb_dropout(self.embedding_layer(src)))\n",
        "        return hc\n",
        "\n",
        "\n",
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedding_layer,\n",
        "                 hidden_size,\n",
        "                 num_layers,\n",
        "                 num_classes,\n",
        "                 lstm_dropout=0.2,\n",
        "                 embedding_dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = embedding_layer\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_dropout = lstm_dropout\n",
        "        self.embedding_dropout = embedding_dropout\n",
        "\n",
        "        self.embedding_layer = embedding_layer #embedding layer is same for both encoder & decoder with emb_dim = hidden_dim\n",
        "        self.emb_dropout = nn.Dropout(p=self.embedding_dropout)\n",
        "        self.rnn = nn.LSTM(input_size=self.hidden_size,\n",
        "                            hidden_size=self.hidden_size,\n",
        "                            num_layers=self.num_layers,\n",
        "                            dropout=self.lstm_dropout,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.proj_layer = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self,\n",
        "                tgt,\n",
        "                hc):\n",
        "\n",
        "        \"\"\"\n",
        "        decoder is autoregressive,\n",
        "        input:\n",
        "            hc-> hidden state from encoder\n",
        "            tgt -> vector of shape [b_size, 1] of current seq input\n",
        "        \"\"\"\n",
        "        tgt = tgt.unsqueeze(1) #adding 1st dim, so we have seq_len == 1\n",
        "\n",
        "        y_pred, hc = self.rnn(self.emb_dropout(self.embedding_layer(tgt)), hc)\n",
        "        #print(y_pred.shape) #for debugging\n",
        "        y_pred = y_pred.squeeze(1)  #going back to [b_size, 100]\n",
        "\n",
        "        return self.proj_layer(y_pred), hc\n",
        "\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 num_layers,\n",
        "                 num_classes,\n",
        "                 vocab_size,\n",
        "                 lstm_dropout=0.2,\n",
        "                 embedding_dropout=0.2):\n",
        "\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes\n",
        "        self.vocab_size = vocab_size\n",
        "        self.lstm_dropout = lstm_dropout\n",
        "        self.embedding_dropout = embedding_dropout\n",
        "\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.encoder = LSTMEncoder(self.embedding_layer,\n",
        "                                   hidden_size,\n",
        "                                   num_layers,\n",
        "                                   lstm_dropout,\n",
        "                                   embedding_dropout)\n",
        "\n",
        "        self.decoder = LSTMDecoder(self.embedding_layer,\n",
        "                                   hidden_size,\n",
        "                                   num_layers,\n",
        "                                   num_classes,\n",
        "                                   lstm_dropout,\n",
        "                                   embedding_dropout)\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing: float=0.5):\n",
        "        hidden_cell = self.encoder(src)\n",
        "#        print(hidden_cell[0].shape, hidden_cell[1].shape)\n",
        "\n",
        "        b_size, max_seq_len =  tgt.shape[0], tgt.shape[1]\n",
        "        input_token = tgt[:, 0]\n",
        "        outputs_seq = torch.zeros(b_size, max_seq_len, self.vocab_size)\n",
        "\n",
        "        for t in range(1, max_seq_len):\n",
        "            output, hidden_cell = self.decoder(input_token, hidden_cell)\n",
        "            outputs_seq[:, t] = output\n",
        "            predicted_token = torch.argmax(output, dim=-1)\n",
        "\n",
        "            do_teacher_forcing = random.random() < teacher_forcing\n",
        "\n",
        "            if do_teacher_forcing:\n",
        "                input_token = tgt[:, t]\n",
        "            else:\n",
        "                input_token = predicted_token\n",
        "\n",
        "\n",
        "        return outputs_seq"
      ],
      "metadata": {
        "id": "oPk58_olP9m3"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 100\n",
        "num_layers=2\n",
        "num_classes = 10\n",
        "vocab_size = 10\n",
        "net = Seq2Seq(hidden_size, num_layers, num_classes, vocab_size)\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "vLgTFiUMRHQ_"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def train_one_epoch(train_dataloader, model, optimizer, loss_fn, epoch, ):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        src, tgt = batch['src'], batch['tgt']\n",
        "        preds = model(src, tgt)\n",
        "        preds = rearrange(preds, 'b s c -> b c s')\n",
        "\n",
        "        loss = loss_fn(preds, tgt)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= idx\n",
        "    print(f'Epoch{epoch}, train_loss: {train_loss}')\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "XpNbMWxcVQq0"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(100)):\n",
        "    train_one_epoch(train_dataloader, net, optimizer, loss_fn, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "51c313b4b2b14583ac5b3a14d0e87ddb",
            "47c3dafc8a7448629136872883719bd2",
            "360d5e90ea8c4e2ea0f01bf031aa7268",
            "0ea3bd9a4c704a0fb1ef490d4f9714ea",
            "1f190959e9434a118254c27ab5d99fd9",
            "b4d46d1423744995bd130fefc6c13af5",
            "281fca9be67247218a7073e4a059387f",
            "74791f810ec14069aedd741798433956",
            "dcd9691abd2f4ee2a65d5c8d371ec75a",
            "f8f8b9f04cf04fd681973399ed2d68b5",
            "b8387396ed2d4350b9a1fd594b56ff27"
          ]
        },
        "id": "HMGdatG9WAnF",
        "outputId": "42c2b3e0-3fe0-4faf-81e2-13c4aa0b54fb"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51c313b4b2b14583ac5b3a14d0e87ddb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch0, train_loss: 2.389103005914127\n",
            "Epoch1, train_loss: 2.000439728007597\n",
            "Epoch2, train_loss: 1.66267491088194\n",
            "Epoch3, train_loss: 1.488317742067225\n",
            "Epoch4, train_loss: 1.325013279914856\n",
            "Epoch5, train_loss: 1.1860505307421965\n",
            "Epoch6, train_loss: 1.0487101568895227\n",
            "Epoch7, train_loss: 0.8977418191292706\n",
            "Epoch8, train_loss: 0.7818280177957871\n",
            "Epoch9, train_loss: 0.7112958641613231\n",
            "Epoch10, train_loss: 0.6617464317994959\n",
            "Epoch11, train_loss: 0.6128384470939636\n",
            "Epoch12, train_loss: 0.595630431876463\n",
            "Epoch13, train_loss: 0.5668694937930387\n",
            "Epoch14, train_loss: 0.5570773236891803\n",
            "Epoch15, train_loss: 0.5436872138696558\n",
            "Epoch16, train_loss: 0.5355622505440432\n",
            "Epoch17, train_loss: 0.5280459803693435\n",
            "Epoch18, train_loss: 0.5218996949055615\n",
            "Epoch19, train_loss: 0.5183721202261308\n",
            "Epoch20, train_loss: 0.5154929564279669\n",
            "Epoch21, train_loss: 0.5113664041547215\n",
            "Epoch22, train_loss: 0.5103302107137793\n",
            "Epoch23, train_loss: 0.5065411592231077\n",
            "Epoch24, train_loss: 0.5034951181972728\n",
            "Epoch25, train_loss: 0.5042783056988436\n",
            "Epoch26, train_loss: 0.501744163386962\n",
            "Epoch27, train_loss: 0.5005773726631614\n",
            "Epoch28, train_loss: 0.5003254816812628\n",
            "Epoch29, train_loss: 0.4989817826186909\n",
            "Epoch30, train_loss: 0.4984021993244396\n",
            "Epoch31, train_loss: 0.4974181494292091\n",
            "Epoch32, train_loss: 0.49582235778079314\n",
            "Epoch33, train_loss: 0.49645915101556215\n",
            "Epoch34, train_loss: 0.49683412208276634\n",
            "Epoch35, train_loss: 0.494108424467199\n",
            "Epoch36, train_loss: 0.49435044912730947\n",
            "Epoch37, train_loss: 0.4939214534619275\n",
            "Epoch38, train_loss: 0.49449142988990336\n",
            "Epoch39, train_loss: 0.49340114873998303\n",
            "Epoch40, train_loss: 0.4928840591627009\n",
            "Epoch41, train_loss: 0.4922986679217395\n",
            "Epoch42, train_loss: 0.4926385826924268\n",
            "Epoch43, train_loss: 0.4918094557874343\n",
            "Epoch44, train_loss: 0.4919419604189256\n",
            "Epoch45, train_loss: 0.4911219933453728\n",
            "Epoch46, train_loss: 0.49091067033655506\n",
            "Epoch47, train_loss: 0.49082307780490203\n",
            "Epoch48, train_loss: 0.4911176036385929\n",
            "Epoch49, train_loss: 0.4906071354361141\n",
            "Epoch50, train_loss: 0.4904623084208545\n",
            "Epoch51, train_loss: 0.4903244113220888\n",
            "Epoch52, train_loss: 0.4901636242866516\n",
            "Epoch53, train_loss: 0.49040531586198244\n",
            "Epoch54, train_loss: 0.4903206141556011\n",
            "Epoch55, train_loss: 0.4903226003927343\n",
            "Epoch56, train_loss: 0.49034151434898376\n",
            "Epoch57, train_loss: 0.48972547930829663\n",
            "Epoch58, train_loss: 0.48965534743140726\n",
            "Epoch59, train_loss: 0.4898645597345689\n",
            "Epoch60, train_loss: 0.48953701117459464\n",
            "Epoch61, train_loss: 0.48940934328471913\n",
            "Epoch62, train_loss: 0.48936521130449634\n",
            "Epoch63, train_loss: 0.48930690569036145\n",
            "Epoch64, train_loss: 0.4892488595317392\n",
            "Epoch65, train_loss: 0.4895739643012776\n",
            "Epoch66, train_loss: 0.489172076477724\n",
            "Epoch67, train_loss: 0.4894089085214278\n",
            "Epoch68, train_loss: 0.4890108634443844\n",
            "Epoch69, train_loss: 0.48909853311146007\n",
            "Epoch70, train_loss: 0.48900211208006916\n",
            "Epoch71, train_loss: 0.48931842165834766\n",
            "Epoch72, train_loss: 0.48931389871765585\n",
            "Epoch73, train_loss: 0.48884817782570333\n",
            "Epoch74, train_loss: 0.4888249653227189\n",
            "Epoch75, train_loss: 0.4887579258750467\n",
            "Epoch76, train_loss: 0.48876993095173554\n",
            "Epoch77, train_loss: 0.4887535729829003\n",
            "Epoch78, train_loss: 0.4886678124175352\n",
            "Epoch79, train_loss: 0.48867251592523914\n",
            "Epoch80, train_loss: 0.488580609069151\n",
            "Epoch81, train_loss: 0.48859284905826345\n",
            "Epoch82, train_loss: 0.48856327112983255\n",
            "Epoch83, train_loss: 0.48880616531652565\n",
            "Epoch84, train_loss: 0.4884776350329904\n",
            "Epoch85, train_loss: 0.4892435932860655\n",
            "Epoch86, train_loss: 0.48848215271444884\n",
            "Epoch87, train_loss: 0.4885978505891912\n",
            "Epoch88, train_loss: 0.48841249241548423\n",
            "Epoch89, train_loss: 0.4893685298807481\n",
            "Epoch90, train_loss: 0.4884364990627064\n",
            "Epoch91, train_loss: 0.48841987462604747\n",
            "Epoch92, train_loss: 0.4883330481893876\n",
            "Epoch93, train_loss: 0.4883223789579728\n",
            "Epoch94, train_loss: 0.4883045641814961\n",
            "Epoch95, train_loss: 0.48866257071495056\n",
            "Epoch96, train_loss: 0.4882580743116491\n",
            "Epoch97, train_loss: 0.48827164313372445\n",
            "Epoch98, train_loss: 0.4882827173261082\n",
            "Epoch99, train_loss: 0.48821690503288717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(batch,  model):\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        src, tgt = batch['src'], batch['tgt']\n",
        "        preds = model(src, tgt)\n",
        "        preds = preds.argmax(dim=-1)\n",
        "\n",
        "    return preds"
      ],
      "metadata": {
        "id": "OOobgdiZWN6s"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = next(iter(test_dataloader))\n",
        "outs = inference(test_input, net)"
      ],
      "metadata": {
        "id": "auowz7fxpdNP"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input['src'][:5], outs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNu5ntwBpjfu",
        "outputId": "55f58212-996b-4077-8e33-7966e0270519"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[9, 1, 1, 3, 0],\n",
              "         [9, 9, 1, 3, 6],\n",
              "         [4, 3, 5, 6, 3],\n",
              "         [6, 9, 2, 0, 0],\n",
              "         [3, 0, 3, 3, 3]]),\n",
              " tensor([[0, 3, 1, 1, 9],\n",
              "         [0, 3, 1, 9, 9],\n",
              "         [0, 6, 5, 3, 4],\n",
              "         [0, 0, 2, 9, 6],\n",
              "         [0, 3, 3, 0, 3]]))"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Q6V3oT5pkHt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}